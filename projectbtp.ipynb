{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPTHZHl_HWKM",
        "outputId": "d5a2e611-0051-4733-ac76-50521c5b0ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsLzbRhrHtf_"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/drive/MyDrive/partial_clustering_random_percentage.zip\" \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyTQBRGaH73w",
        "outputId": "aa06a9f8-1b11-4832-cb68-1afe9a973ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/partial_clustering_random_percentage.zip\n",
            "   creating: partial_clustering_random_percentage/\n",
            "  inflating: partial_clustering_random_percentage/vgg_pruningmethod.py  \n",
            "  inflating: partial_clustering_random_percentage/partial_clustering.py  \n",
            "  inflating: partial_clustering_random_percentage/VGG16.py  \n",
            "  inflating: partial_clustering_random_percentage/vgg_network_prune.py  \n",
            "  inflating: partial_clustering_random_percentage/epoch_295.pth  \n",
            "   creating: partial_clustering_random_percentage/__pycache__/\n",
            "  inflating: partial_clustering_random_percentage/__pycache__/vgg_pruningmethod.cpython-36.pyc  \n",
            "  inflating: partial_clustering_random_percentage/__pycache__/vgg_network_prune.cpython-36.pyc  \n",
            "  inflating: partial_clustering_random_percentage/__pycache__/VGG16.cpython-36.pyc  \n",
            "   creating: partial_clustering_random_percentage/data/\n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-python.tar.gz  \n",
            "   creating: partial_clustering_random_percentage/checkpoint/\n",
            "  inflating: partial_clustering_random_percentage/checkpoint/ckpt.t7  \n",
            "   creating: partial_clustering_random_percentage/data/cifar-10-batches-py/\n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/test_batch  \n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/data_batch_4  \n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/data_batch_3  \n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/data_batch_5  \n",
            " extracting: partial_clustering_random_percentage/data/cifar-10-batches-py/readme.html  \n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/data_batch_1  \n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/data_batch_2  \n",
            "  inflating: partial_clustering_random_percentage/data/cifar-10-batches-py/batches.meta  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/partial_clustering_random_percentage.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcXJcbCeKgAk"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/partial_clustering_random_percentage/epoch_295.pth\" \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcZGhWOcKm-I"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/partial_clustering_random_percentage/checkpoint/ckpt.t7\" \"/content/checkpoint\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSaxDDJQJmaW"
      },
      "source": [
        "vgg_network_prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4iu-Nu5IE3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from numpy.linalg import norm\n",
        "#import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "import csv \n",
        "from time import localtime, strftime\n",
        "import os \n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "import scipy.cluster.hierarchy as hcluster\n",
        "import scipy.cluster.hierarchy as hac\n",
        "import scipy.cluster.hierarchy as fclusterdata\n",
        "import time\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import math\n",
        "\n",
        "seed = 1787\n",
        "#random.seed(seed)\n",
        "#import os\n",
        "#os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "#th.manual_seed(seed)\n",
        "#th.cuda.manual_seed(seed)\n",
        "#th.cuda.manual_seed_all(seed)\n",
        "#th.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "class Network():\n",
        "\n",
        "    def weight_init(self, m):\n",
        "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "            if self.a_type == 'relu':\n",
        "                init.kaiming_normal_(m.weight.data, nonlinearity=self.a_type)\n",
        "                init.constant_(m.bias.data, 0)\n",
        "            elif self.a_type == 'leaky_relu':\n",
        "                init.kaiming_normal_(m.weight.data, nonlinearity=self.a_type)\n",
        "                init.constant_(m.bias.data, 0)\n",
        "            elif self.a_type == 'tanh':\n",
        "                g = init.calculate_gain(self.a_type)\n",
        "                init.xavier_uniform_(m.weight.data, gain=g)\n",
        "                init.constant_(m.bias.data, 0)\n",
        "            elif self.a_type == 'sigmoid':\n",
        "                g = init.calculate_gain(self.a_type)\n",
        "                init.xavier_uniform_(m.weight.data, gain=g)\n",
        "                init.constant_(m.bias.data, 0)\n",
        "            else:\n",
        "                raise\n",
        "                return NotImplemented\n",
        "\n",
        "    \n",
        "    def create_folders(self,total_convs):\n",
        "\n",
        "      main_dir=strftime('/content/drive/MyDrive/BTP/sem7\\\\Results\\\\%b%d_%H_%M_%S%p', localtime() )+\"_vgg\"\n",
        "\n",
        "      # temp=strftime('%b%d_%H:%M:%S%p', localtime() )+\"_vgg\"\n",
        "      # temp = \"\\\\Sep27_21:\"\n",
        "      # print(temp)\n",
        "\n",
        "      import os\n",
        "      current_dir =  os.path.abspath(os.path.dirname(\"/content/drive/MyDrive/BTP/sem7\"))\n",
        "      par_dir = os.path.abspath(current_dir + \"/../\")\n",
        "      print(par_dir)\n",
        "      par_dir=os.path.dirname(os.path.realpath(\"/content\"))\n",
        "      print(par_dir)\n",
        "      parent_dir=par_dir+main_dir\n",
        " \n",
        "      for i in range(total_convs):\n",
        "        path1=os.path.join(main_dir, \"conv\"+str(i+1))\n",
        "        print(path1)\n",
        "        os.makedirs(path1)\n",
        "      return parent_dir\n",
        "\n",
        "    def get_writerow(self,k):\n",
        "\n",
        "      s='wr.writerow(['\n",
        "\n",
        "      for i in range(k):\n",
        "\n",
        "          s=s+'d['+str(i)+']'\n",
        "\n",
        "          if(i<k-1):\n",
        "             s=s+','\n",
        "          else:\n",
        "             s=s+'])'\n",
        "\n",
        "      return s\n",
        "\n",
        "    def get_logger(self,file_path):\n",
        "\n",
        "        logger = logging.getLogger('gal')\n",
        "        log_format = '%(asctime)s | %(message)s'\n",
        "        formatter = logging.Formatter(log_format, datefmt='%m/%d %I:%M:%S %p')\n",
        "        file_handler = logging.FileHandler(file_path)\n",
        "        file_handler.setFormatter(formatter)\n",
        "        stream_handler = logging.StreamHandler()\n",
        "        stream_handler.setFormatter(formatter)\n",
        "\n",
        "        logger.addHandler(file_handler)\n",
        "        logger.addHandler(stream_handler)\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        return logger\n",
        "\n",
        "    def cluster_weights_agglo(self,weight, threshold,prunes,folder_name,conv_layer,first=False, average=True):\n",
        "        #t0 = time.time()\n",
        "        #print(type(weight))\n",
        "        #print('1...',weight.shape)\n",
        "        weight = weight.T\n",
        "        #print('1...',weight.shape, type(weight))\n",
        "        weight = normalize(weight, norm='l2', axis=1)\n",
        "        #print('2...',weight.shape)\n",
        "        threshold =  1.0-threshold   # Conversion to distance measure\n",
        "        #clusters = hcluster.fclusterdata(weight, threshold, criterion=\"distance\", metric='cosine', depth=1, method='centroid')\n",
        "        z = hac.linkage(weight, metric='cosine', method='complete')\n",
        "\n",
        "        #print('z.......',len(z))\n",
        "        labels = hac.fcluster(z, threshold, criterion=\"distance\")\n",
        "        #print('lables...',labels)\n",
        "       \n",
        "        #print('sorted lables...',len(labels),np.sort(labels))\n",
        "\n",
        "        labels_unique = np.unique(labels)\n",
        "        #print('labels_unique...',labels_unique.shape,labels_unique)\n",
        "        n_clusters_ = len(labels_unique)\n",
        "\n",
        "        a=np.array(labels)\n",
        "        #print('a....',a)\n",
        "        sort_idx = np.argsort(a)\n",
        "        #print('sorted idx...',len(sort_idx), sort_idx)\n",
        "        a_sorted1 = a[sort_idx]\n",
        "        #print('a_sorted...',len(a_sorted1), a_sorted1, type(a_sorted1))\n",
        "\n",
        "\n",
        "        if(first==False): #ONLY 1 from each cluster\n",
        "\n",
        "            unq_first = np.concatenate(([True], a_sorted1[1:] != a_sorted1[:-1]))\n",
        "            #print('unq_first...',len(unq_first), unq_first)\n",
        "\n",
        "            unq_items = a_sorted1[unq_first]\n",
        "            unq_count = np.diff(np.nonzero(unq_first)[0])\n",
        "            unq_idx = np.split(sort_idx, np.cumsum(unq_count))\n",
        "            first_ele = [unq_idx[idx][-1] for idx in range(len(unq_idx))]\n",
        "        else: # % of filters from each cluster\n",
        "            a_sorted= np.sort(labels)\n",
        "            val2= sort_idx\n",
        "            temp=[] \n",
        "            filters=[]      \n",
        "            for i in range(len(a_sorted)):\n",
        "\t\t\t   \n",
        "                val=a_sorted[i]\n",
        "\t\t\n",
        "                if (i== len(a_sorted)-1 ):\n",
        "                      #print('True', val2[i])\n",
        "                      temp.append(val2[i])\n",
        "                      filters.append(temp)\n",
        "                      temp=[]\n",
        "\t\t\t\t\n",
        "                elif(i!= len(a_sorted)-1 and (val != a_sorted[i+1])):\n",
        "                      #print('True', val2[i])\n",
        "                      temp.append(val2[i])\n",
        "                      filters.append(temp)\n",
        "                      temp=[]\n",
        "                else:\n",
        "                      #print('False')\n",
        "                      temp.append(val2[i])\n",
        "            #print(filters)\n",
        "\n",
        "            #sort each cluster based on each weighs L1/L2 norm and plot histogram\n",
        "            l1_norms=[]\n",
        "            for i in range(len(filters)):\n",
        "               temp=[]\n",
        "               for f in filters[i]:\n",
        "                 #print(i,'...',weight[f].shape,'....',norm(weight[f],2), norm(weight[f],1))\n",
        "                 #print(weight[f])\n",
        "                 temp.append(norm(weight[f],1)) #L1-norm\n",
        "               l1_norms.append(np.around(temp,3))  \n",
        "\n",
        "            #____________SORTING FILTERS BASED ON L1 NORM________\n",
        "            '''sorted_filters=[]\n",
        "            for i in range(len(filters)):\n",
        "                 sorted_filters.append( [x for _,x in sorted(zip(l1_norms[i],filters[i]))] )'''\n",
        "\n",
        "\n",
        "            # for i in range(len(l1_norms)):\n",
        "            #      plt.hist(l1_norms[i], weights=np.ones(len(l1_norms[i])) / len(l1_norms[i]))\n",
        "            #      plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "            #      plt.savefig(folder_name+\"/c\"+str(i+1)+\".png\")\n",
        "            #      plt.clf()\n",
        "            #      plt.cla()\n",
        "            #      plt.close()\n",
        "\n",
        "\n",
        "\n",
        "            #filters=sorted_filters #_____COMMENT OUT FOR random pruning___\n",
        "            ele=[]\n",
        "            for j in range(len(filters)):\n",
        "\n",
        "                if(len(filters[j])==1):\n",
        "                  cut=0\n",
        "                else:\n",
        "                  cut= math.ceil(len(filters[j])/4) #prune 25% only\n",
        "\n",
        "                retain_filters= filters[j][cut:]\n",
        "                ele.extend(retain_filters)\n",
        "                #print('total=',len(filters[j]),' remaining=',len(retain_filters),'  index=',cut)\n",
        "            #print(ele)\n",
        "            first_ele=ele\n",
        "\n",
        "        \n",
        "\n",
        "        #print('first ele.....',len(first_ele))\n",
        "        return n_clusters_, first_ele\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kBxOJHBJq5d"
      },
      "source": [
        "vgg_pruningmethod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Sv2rSopIK7_"
      },
      "outputs": [],
      "source": [
        "import torch as th\n",
        "import torch.nn as nn \n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#seed = 1787\n",
        "#np.random.seed(seed)\n",
        "\n",
        "filters_selected=[]\n",
        "#filters_remaining=[]\n",
        "no_of_dimensions=-1\n",
        "\n",
        "#prune_percentage=[0.02]*2+[0.04]*2+[0.05]*3+[0.1]*6\n",
        "class PruningMethod():\n",
        "\n",
        "   \n",
        "    def prune_filters(self,threshold,prunes,folder_name):\n",
        "      conv_layer=0\n",
        "      total=None #-------\n",
        "      first_ele= None #-------\n",
        "      #nb_remanining_filters = []\n",
        "      print(prunes)\n",
        "  \n",
        "      for layer_name, layer in self.named_modules():\n",
        "        #print(layer_name)\n",
        "\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "\n",
        "            #CREATE PRUNE STEP FOLDER\n",
        "            path1=os.path.join(folder_name+\"conv\"+str(conv_layer+1)+\"/prune\"+str(prunes))\n",
        "            os.makedirs(path1)\n",
        "\n",
        "            #print(layer_name)\n",
        "            weight = layer.weight.data.cpu().numpy()\n",
        "            bias = layer.bias.data.cpu().numpy()\n",
        "            #print('1..',weight.shape)\n",
        "            if first_ele is not None:\n",
        "                weight_layers_rearranged = np.transpose(weight, (1, 0, 2, 3))\n",
        "                weight_layers_rearranged_pruned = weight_layers_rearranged[first_ele]\n",
        "                weight_layers_rearranged_pruned = np.transpose(weight_layers_rearranged_pruned, (1, 0, 2, 3))\n",
        "            else:\n",
        "                weight_layers_rearranged_pruned = weight\n",
        "            #print('2a...',weight_layers_rearranged_pruned.shape)\n",
        "            weight_layers_rearranged = np.reshape(weight_layers_rearranged_pruned, [weight_layers_rearranged_pruned.shape[0], -1])\n",
        "            #print('3a.....',weight_layers_rearranged.shape)\n",
        "            if(prunes>20): #if(prunes!=0):\n",
        "               #print('NORMAL  calling.....')\n",
        "               n_clusters_,first_ele = self.cluster_weights_agglo(weight_layers_rearranged.T, threshold,prunes,path1,conv_layer) \n",
        "            else:\n",
        "               #print('calling.....')\n",
        "               n_clusters_,first_ele = self.cluster_weights_agglo(weight_layers_rearranged.T, threshold,prunes,path1,conv_layer, first=True) #50% pruning\n",
        "\n",
        "\n",
        "            conv_layer+=1\n",
        "\n",
        "\n",
        "\n",
        "            first_ele = sorted(first_ele)\n",
        "\n",
        "            weight_pruned = weight_layers_rearranged[first_ele]\n",
        "            #print('4..',weight_pruned.shape)\n",
        "            bias_pruned = bias[first_ele]\n",
        "\n",
        "\n",
        "            weight_pruned = np.reshape(weight_pruned, [len(first_ele), weight_layers_rearranged_pruned.shape[1],weight_layers_rearranged_pruned.shape[2],weight_layers_rearranged_pruned.shape[3]])\n",
        "            #print('5..',weight_pruned.shape)\n",
        "\n",
        "            params_1 = np.shape(weight_pruned)\n",
        "            layer.out_channels = params_1[0]\n",
        "            layer.in_channels = params_1[1]\n",
        "\n",
        "            weight_tensor = th.from_numpy(weight_pruned)\n",
        "            bias_tensor = th.from_numpy(bias_pruned)\n",
        "            layer.weight = th.nn.Parameter(weight_tensor)\n",
        "            layer.bias = th.nn.Parameter(bias_tensor)\n",
        "\n",
        "           \n",
        "            #ii+=1\n",
        "            #rr+=1\n",
        "\n",
        "        if isinstance(layer, nn.BatchNorm2d) and first_ele is not None:\n",
        "            bnorm_weight = layer.weight.data.cpu().numpy()\n",
        "            bnorm_weight = bnorm_weight[first_ele]\n",
        "            bnorm_bias = layer.bias.data.cpu().numpy()\n",
        "            bnorm_bias = bnorm_bias[first_ele]\n",
        "\n",
        "            bnorm_tensor = th.from_numpy(bnorm_weight)\n",
        "            bias_tensor = th.from_numpy(bnorm_bias)\n",
        "            layer.weight = th.nn.Parameter(bnorm_tensor)\n",
        "            layer.bias = th.nn.Parameter(bias_tensor)\n",
        "\n",
        "            layer.num_features = int(np.shape(bnorm_weight)[0])\n",
        "            bnorm_rm = layer.running_mean.cpu().numpy()\n",
        "            bnorm_rm = bnorm_rm[first_ele]\n",
        "            bnorm_rv = layer.running_var.cpu().numpy()\n",
        "            bnorm_rv = bnorm_rv[first_ele]\n",
        "            running_mean = th.from_numpy(bnorm_rm)\n",
        "            layer.running_mean = running_mean\n",
        "            running_var = th.from_numpy(bnorm_rv)\n",
        "            layer.running_var = running_var\n",
        "            #rr+=1\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            weight_linear = layer.weight.data.cpu().numpy()\n",
        "            #print('1...',weight_linear.shape)\n",
        "            weight_linear_rearranged = np.transpose(weight_linear, (1, 0))\n",
        "            weight_linear_rearranged_pruned = weight_linear_rearranged[first_ele]\n",
        "            weight_linear_rearranged_pruned = np.transpose(weight_linear_rearranged_pruned, (1, 0))\n",
        "            #print('2....',weight_linear_rearranged_pruned.shape)\n",
        "\n",
        "            layer.in_features = int(np.shape(weight_linear_rearranged_pruned)[1])\n",
        "            linear_tensor = th.from_numpy(weight_linear_rearranged_pruned)\n",
        "            layer.weight = th.nn.Parameter(linear_tensor)\n",
        "            break\n",
        "\n",
        "           \n",
        "            \n",
        "\n",
        "      \n",
        "    def get_indices_topk(self,layer_bounds,i,prune_limit,prune_percentage):\n",
        "\n",
        "      #global prune_percentage\n",
        "      indices=int(len(layer_bounds)*prune_percentage[i])+1 #1\n",
        "      p=len(layer_bounds) #3\n",
        "      if (p-indices)<prune_limit: #3-1<3\n",
        "         remaining=p-prune_limit\n",
        "         indices=remaining\n",
        "      k=sorted(range(len(layer_bounds)), key=lambda j: layer_bounds[j])[:indices]\n",
        "      #print('indidces',k, 'len ',len(layer_bounds))\n",
        "      return k\n",
        "\n",
        "    def get_indices_bottomk(self,layer_bounds,i,prune_limit):\n",
        "\n",
        "      k=sorted(range(len(layer_bounds)), key=lambda j: layer_bounds[j])[-prune_limit:]\n",
        "      #print('indidces',k, 'len ',len(layer_bounds))\n",
        "      return k\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ0Tsm73JuXX"
      },
      "source": [
        "vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "ZN1FsydzIXdi",
        "outputId": "b2182d2f-9a60-47e2-e3fd-82e1252b7152"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\\nmodel_tupry = VGG16(10,\\'relu\\',100).to(device)\\n\\na=model_tupry(th.randn(1, 3, 32, 32).cuda())\\nfor i in range(15):\\n\\tprint(\\'layer \\',str(i),\\' \\',a[i].shape)\\n#for name, layer_module in model_tupry.named_modules():\\n#  if(isinstance(layer_module, th.nn.Conv2d)):\\n#    a.append(layer_module.shape)\\n#---------intialize layer numbers and names dictionary------\\nmodel_tupry.intialize_layer_name_num(model_tupry)\\n\\n#---------intialize pruned and remaning filters-----------\\nmodel_tupry.filters_in_each_layer(model_tupry)\\n \\n#--------calculate remaining filters in each epoch--------\\nmodel_tupry.remaining_filters_per_epoch(model=model_tupry,initial=True)\\nmodel_tupry.calculate_total_flops(model_tupry)\\nimport sys\\nsys.exit()\\nfor layer_name, layer_module in model_tupry.named_modules():\\n           if(isinstance(layer_module, th.nn.Conv2d) or  isinstance(layer_module,th.nn.Linear)):\\n              print(layer_name,\\'-------\\',layer_module,\\'---------\\',layer_module.weight.size()[0])'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch as th\n",
        "import torch.nn as nn\n",
        "# from vgg_network_prune import Network\n",
        "# from  vgg_pruningmethod import PruningMethod\n",
        "#from torchsummary import summary\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "\n",
        "class VGG16(nn.Module,Network,PruningMethod):\n",
        "    def __init__(self, n_c, a_type):\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        self.a_type = a_type\n",
        "\n",
        "        if a_type == 'relu':\n",
        "            self.activation = nn.ReLU()\n",
        "        elif a_type == 'tanh':\n",
        "            self.activation = nn.Tanh()\n",
        "        elif a_type == 'sigmoid':\n",
        "            self.activation = nn.Sigmoid()\n",
        "        elif a_type == 'leaky_relu':\n",
        "            self.activation = nn.LeakyReLU()\n",
        "        else:\n",
        "            print('Not implemented')\n",
        "            raise\n",
        "\n",
        "        # First encoder\n",
        "        self.layer1 = nn.Sequential(\n",
        "                *([nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(64),\n",
        "                   self.activation]))\n",
        "        self.layer2 = nn.Sequential(\n",
        "                *([nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(64),\n",
        "                   self.activation]))\n",
        "        # Second encoder\n",
        "        self.layer3 = nn.Sequential(\n",
        "                *([nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(128),\n",
        "                   self.activation]))\n",
        "        self.layer4 = nn.Sequential(\n",
        "                *([nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(128),\n",
        "                   self.activation]))\n",
        "\n",
        "        # Third encoder\n",
        "        self.layer5 = nn.Sequential(\n",
        "                *([nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(256),\n",
        "                   self.activation]))\n",
        "        self.layer6 = nn.Sequential(\n",
        "                *([nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(256),\n",
        "                   self.activation]))\n",
        "        self.layer7 = nn.Sequential(\n",
        "                *([nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(256),\n",
        "                   self.activation]))\n",
        "\n",
        "        # Fourth encoder\n",
        "        self.layer8 = nn.Sequential(\n",
        "                *([nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(512),\n",
        "                   self.activation]))\n",
        "        self.layer9 = nn.Sequential(\n",
        "                *([nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(512),\n",
        "                   self.activation]))\n",
        "        self.layer10 = nn.Sequential(\n",
        "                *([nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(512),\n",
        "                   self.activation]))\n",
        "\n",
        "        # Fifth encoder\n",
        "        self.layer11 = nn.Sequential(\n",
        "                *([nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(512),\n",
        "                   self.activation]))\n",
        "        self.layer12 = nn.Sequential(\n",
        "                *([nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(512),\n",
        "                   self.activation]))\n",
        "        self.layer13 = nn.Sequential(\n",
        "                *([nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "                   nn.BatchNorm2d(512),\n",
        "                   self.activation]))\n",
        "\n",
        "        # Classifier\n",
        "        self.fc1 = nn.Sequential(*([\n",
        "                nn.Linear(512, 512),\n",
        "                nn.BatchNorm1d(512),\n",
        "                self.activation]))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                *([nn.Linear(512, n_c),]))\n",
        "\n",
        "        for m in self.modules():\n",
        "            self.weight_init(m)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "        self.layer_name_num={}\n",
        "        self.pruned_filters={}\n",
        "        self.remaining_filters={}\n",
        "\n",
        "        self.remaining_filters_each_epoch=[]\n",
        "\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Encoder 2\n",
        "        layer1 = self.layer1(x)\n",
        "        layer2 = self.layer2(layer1)\n",
        "        pool1 = self.pool(layer2)\n",
        "\n",
        "        # Encoder 2\n",
        "        layer3 = self.layer3(pool1)\n",
        "        layer4 = self.layer4(layer3)\n",
        "        pool2 = self.pool(layer4)\n",
        "\n",
        "        # Encoder 3\n",
        "        layer5 = self.layer5(pool2)\n",
        "        layer6 = self.layer6(layer5)\n",
        "        layer7 = self.layer7(layer6)\n",
        "        pool3 = self.pool(layer7)\n",
        "\n",
        "        # Encoder 4\n",
        "        layer8 = self.layer8(pool3)\n",
        "        layer9 = self.layer9(layer8)\n",
        "        layer10 = self.layer10(layer9)\n",
        "        pool4 = self.pool(layer10)\n",
        "\n",
        "        # Encoder 5\n",
        "        layer11 = self.layer11(pool4)\n",
        "        layer12 = self.layer12(layer11)\n",
        "        \n",
        "        layer13 = self.layer13(layer12)\n",
        "        #pool5 = self.pool(layer13)\n",
        "        #print(layer13.shape)\n",
        "\n",
        "        #avgpool \n",
        "        avg_x=nn.AvgPool2d(2)(layer13)\n",
        "        #print(avg_x.shape)\n",
        "\n",
        "        # Classifier\n",
        "        fc1 = self.fc1(avg_x.view(avg_x.size(0), -1))\n",
        "        #print(fc1.shape)\n",
        "        \n",
        "        classifier = self.classifier(fc1)\n",
        "        return classifier\n",
        "\n",
        "\n",
        "'''device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
        "model_tupry = VGG16(10,'relu',100).to(device)\n",
        "\n",
        "a=model_tupry(th.randn(1, 3, 32, 32).cuda())\n",
        "for i in range(15):\n",
        "\tprint('layer ',str(i),' ',a[i].shape)\n",
        "#for name, layer_module in model_tupry.named_modules():\n",
        "#  if(isinstance(layer_module, th.nn.Conv2d)):\n",
        "#    a.append(layer_module.shape)\n",
        "#---------intialize layer numbers and names dictionary------\n",
        "model_tupry.intialize_layer_name_num(model_tupry)\n",
        "\n",
        "#---------intialize pruned and remaning filters-----------\n",
        "model_tupry.filters_in_each_layer(model_tupry)\n",
        " \n",
        "#--------calculate remaining filters in each epoch--------\n",
        "model_tupry.remaining_filters_per_epoch(model=model_tupry,initial=True)\n",
        "model_tupry.calculate_total_flops(model_tupry)\n",
        "import sys\n",
        "sys.exit()\n",
        "for layer_name, layer_module in model_tupry.named_modules():\n",
        "           if(isinstance(layer_module, th.nn.Conv2d) or  isinstance(layer_module,th.nn.Linear)):\n",
        "              print(layer_name,'-------',layer_module,'---------',layer_module.weight.size()[0])'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPfaVmp0JxWG"
      },
      "source": [
        "partial_clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgIgsmr1IZHx",
        "outputId": "623212c5-e11c-4117-c47c-10f129159da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/content/drive/MyDrive\n",
            "/\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv1\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv2\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv3\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv4\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv5\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv6\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv7\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv8\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv9\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv10\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv11\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv12\n",
            "/content/drive/MyDrive/BTP/sem7\\Results\\Sep27_20_22_47PM_vgg/conv13\n",
            "loading completed\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 08:27:04 PM | [44, 57, 125, 128, 256, 256, 256, 422, 352, 345, 370, 374, 375]\n",
            "09/27 08:27:04 PM | [44, 57, 125, 128, 256, 256, 256, 422, 352, 345, 370, 374, 375]\n",
            "INFO:gal:[44, 57, 125, 128, 256, 256, 256, 422, 352, 345, 370, 374, 375]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new-model starts....for  90  epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 08:27:41 PM | Epoch: 0/89---Train:92.824----Test: 87.380\n",
            "\n",
            "09/27 08:27:41 PM | Epoch: 0/89---Train:92.824----Test: 87.380\n",
            "\n",
            "INFO:gal:Epoch: 0/89---Train:92.824----Test: 87.380\n",
            "\n",
            "09/27 08:28:12 PM | Epoch: 1/89---Train:94.232----Test: 89.130\n",
            "\n",
            "09/27 08:28:12 PM | Epoch: 1/89---Train:94.232----Test: 89.130\n",
            "\n",
            "INFO:gal:Epoch: 1/89---Train:94.232----Test: 89.130\n",
            "\n",
            "09/27 08:28:42 PM | Epoch: 2/89---Train:94.790----Test: 89.120\n",
            "\n",
            "09/27 08:28:42 PM | Epoch: 2/89---Train:94.790----Test: 89.120\n",
            "\n",
            "INFO:gal:Epoch: 2/89---Train:94.790----Test: 89.120\n",
            "\n",
            "09/27 08:29:13 PM | Epoch: 3/89---Train:95.196----Test: 89.840\n",
            "\n",
            "09/27 08:29:13 PM | Epoch: 3/89---Train:95.196----Test: 89.840\n",
            "\n",
            "INFO:gal:Epoch: 3/89---Train:95.196----Test: 89.840\n",
            "\n",
            "09/27 08:29:44 PM | Epoch: 4/89---Train:95.788----Test: 89.510\n",
            "\n",
            "09/27 08:29:44 PM | Epoch: 4/89---Train:95.788----Test: 89.510\n",
            "\n",
            "INFO:gal:Epoch: 4/89---Train:95.788----Test: 89.510\n",
            "\n",
            "09/27 08:30:15 PM | Epoch: 5/89---Train:95.836----Test: 90.150\n",
            "\n",
            "09/27 08:30:15 PM | Epoch: 5/89---Train:95.836----Test: 90.150\n",
            "\n",
            "INFO:gal:Epoch: 5/89---Train:95.836----Test: 90.150\n",
            "\n",
            "09/27 08:30:47 PM | Epoch: 6/89---Train:96.104----Test: 89.670\n",
            "\n",
            "09/27 08:30:47 PM | Epoch: 6/89---Train:96.104----Test: 89.670\n",
            "\n",
            "INFO:gal:Epoch: 6/89---Train:96.104----Test: 89.670\n",
            "\n",
            "09/27 08:31:19 PM | Epoch: 7/89---Train:96.180----Test: 90.540\n",
            "\n",
            "09/27 08:31:19 PM | Epoch: 7/89---Train:96.180----Test: 90.540\n",
            "\n",
            "INFO:gal:Epoch: 7/89---Train:96.180----Test: 90.540\n",
            "\n",
            "09/27 08:31:50 PM | Epoch: 8/89---Train:96.326----Test: 89.080\n",
            "\n",
            "09/27 08:31:50 PM | Epoch: 8/89---Train:96.326----Test: 89.080\n",
            "\n",
            "INFO:gal:Epoch: 8/89---Train:96.326----Test: 89.080\n",
            "\n",
            "09/27 08:32:22 PM | Epoch: 9/89---Train:96.206----Test: 90.290\n",
            "\n",
            "09/27 08:32:22 PM | Epoch: 9/89---Train:96.206----Test: 90.290\n",
            "\n",
            "INFO:gal:Epoch: 9/89---Train:96.206----Test: 90.290\n",
            "\n",
            "09/27 08:32:53 PM | Epoch: 10/89---Train:96.626----Test: 90.550\n",
            "\n",
            "09/27 08:32:53 PM | Epoch: 10/89---Train:96.626----Test: 90.550\n",
            "\n",
            "INFO:gal:Epoch: 10/89---Train:96.626----Test: 90.550\n",
            "\n",
            "09/27 08:33:26 PM | Epoch: 11/89---Train:96.554----Test: 90.860\n",
            "\n",
            "09/27 08:33:26 PM | Epoch: 11/89---Train:96.554----Test: 90.860\n",
            "\n",
            "INFO:gal:Epoch: 11/89---Train:96.554----Test: 90.860\n",
            "\n",
            "09/27 08:33:57 PM | Epoch: 12/89---Train:96.646----Test: 89.880\n",
            "\n",
            "09/27 08:33:57 PM | Epoch: 12/89---Train:96.646----Test: 89.880\n",
            "\n",
            "INFO:gal:Epoch: 12/89---Train:96.646----Test: 89.880\n",
            "\n",
            "09/27 08:34:29 PM | Epoch: 13/89---Train:96.864----Test: 89.930\n",
            "\n",
            "09/27 08:34:29 PM | Epoch: 13/89---Train:96.864----Test: 89.930\n",
            "\n",
            "INFO:gal:Epoch: 13/89---Train:96.864----Test: 89.930\n",
            "\n",
            "09/27 08:35:01 PM | Epoch: 14/89---Train:96.764----Test: 90.350\n",
            "\n",
            "09/27 08:35:01 PM | Epoch: 14/89---Train:96.764----Test: 90.350\n",
            "\n",
            "INFO:gal:Epoch: 14/89---Train:96.764----Test: 90.350\n",
            "\n",
            "09/27 08:35:32 PM | Epoch: 15/89---Train:96.848----Test: 89.660\n",
            "\n",
            "09/27 08:35:32 PM | Epoch: 15/89---Train:96.848----Test: 89.660\n",
            "\n",
            "INFO:gal:Epoch: 15/89---Train:96.848----Test: 89.660\n",
            "\n",
            "09/27 08:36:05 PM | Epoch: 16/89---Train:96.940----Test: 90.510\n",
            "\n",
            "09/27 08:36:05 PM | Epoch: 16/89---Train:96.940----Test: 90.510\n",
            "\n",
            "INFO:gal:Epoch: 16/89---Train:96.940----Test: 90.510\n",
            "\n",
            "09/27 08:36:37 PM | Epoch: 17/89---Train:96.936----Test: 89.570\n",
            "\n",
            "09/27 08:36:37 PM | Epoch: 17/89---Train:96.936----Test: 89.570\n",
            "\n",
            "INFO:gal:Epoch: 17/89---Train:96.936----Test: 89.570\n",
            "\n",
            "09/27 08:37:08 PM | Epoch: 18/89---Train:96.954----Test: 90.750\n",
            "\n",
            "09/27 08:37:08 PM | Epoch: 18/89---Train:96.954----Test: 90.750\n",
            "\n",
            "INFO:gal:Epoch: 18/89---Train:96.954----Test: 90.750\n",
            "\n",
            "09/27 08:37:40 PM | Epoch: 19/89---Train:97.048----Test: 90.250\n",
            "\n",
            "09/27 08:37:40 PM | Epoch: 19/89---Train:97.048----Test: 90.250\n",
            "\n",
            "INFO:gal:Epoch: 19/89---Train:97.048----Test: 90.250\n",
            "\n",
            "09/27 08:38:12 PM | Epoch: 20/89---Train:96.996----Test: 90.150\n",
            "\n",
            "09/27 08:38:12 PM | Epoch: 20/89---Train:96.996----Test: 90.150\n",
            "\n",
            "INFO:gal:Epoch: 20/89---Train:96.996----Test: 90.150\n",
            "\n",
            "09/27 08:38:44 PM | Epoch: 21/89---Train:97.032----Test: 90.250\n",
            "\n",
            "09/27 08:38:44 PM | Epoch: 21/89---Train:97.032----Test: 90.250\n",
            "\n",
            "INFO:gal:Epoch: 21/89---Train:97.032----Test: 90.250\n",
            "\n",
            "09/27 08:39:16 PM | Epoch: 22/89---Train:97.030----Test: 90.130\n",
            "\n",
            "09/27 08:39:16 PM | Epoch: 22/89---Train:97.030----Test: 90.130\n",
            "\n",
            "INFO:gal:Epoch: 22/89---Train:97.030----Test: 90.130\n",
            "\n",
            "09/27 08:39:48 PM | Epoch: 23/89---Train:96.938----Test: 89.820\n",
            "\n",
            "09/27 08:39:48 PM | Epoch: 23/89---Train:96.938----Test: 89.820\n",
            "\n",
            "INFO:gal:Epoch: 23/89---Train:96.938----Test: 89.820\n",
            "\n",
            "09/27 08:40:19 PM | Epoch: 24/89---Train:97.198----Test: 90.100\n",
            "\n",
            "09/27 08:40:19 PM | Epoch: 24/89---Train:97.198----Test: 90.100\n",
            "\n",
            "INFO:gal:Epoch: 24/89---Train:97.198----Test: 90.100\n",
            "\n",
            "09/27 08:40:51 PM | Epoch: 25/89---Train:97.190----Test: 89.930\n",
            "\n",
            "09/27 08:40:51 PM | Epoch: 25/89---Train:97.190----Test: 89.930\n",
            "\n",
            "INFO:gal:Epoch: 25/89---Train:97.190----Test: 89.930\n",
            "\n",
            "09/27 08:41:24 PM | Epoch: 26/89---Train:97.160----Test: 90.190\n",
            "\n",
            "09/27 08:41:24 PM | Epoch: 26/89---Train:97.160----Test: 90.190\n",
            "\n",
            "INFO:gal:Epoch: 26/89---Train:97.160----Test: 90.190\n",
            "\n",
            "09/27 08:41:55 PM | Epoch: 27/89---Train:97.190----Test: 89.930\n",
            "\n",
            "09/27 08:41:55 PM | Epoch: 27/89---Train:97.190----Test: 89.930\n",
            "\n",
            "INFO:gal:Epoch: 27/89---Train:97.190----Test: 89.930\n",
            "\n",
            "09/27 08:42:27 PM | Epoch: 28/89---Train:97.144----Test: 88.980\n",
            "\n",
            "09/27 08:42:27 PM | Epoch: 28/89---Train:97.144----Test: 88.980\n",
            "\n",
            "INFO:gal:Epoch: 28/89---Train:97.144----Test: 88.980\n",
            "\n",
            "09/27 08:42:58 PM | Epoch: 29/89---Train:96.952----Test: 90.740\n",
            "\n",
            "09/27 08:42:58 PM | Epoch: 29/89---Train:96.952----Test: 90.740\n",
            "\n",
            "INFO:gal:Epoch: 29/89---Train:96.952----Test: 90.740\n",
            "\n",
            "09/27 08:43:30 PM | Epoch: 30/89---Train:97.212----Test: 89.790\n",
            "\n",
            "09/27 08:43:30 PM | Epoch: 30/89---Train:97.212----Test: 89.790\n",
            "\n",
            "INFO:gal:Epoch: 30/89---Train:97.212----Test: 89.790\n",
            "\n",
            "09/27 08:44:03 PM | Epoch: 31/89---Train:97.182----Test: 90.190\n",
            "\n",
            "09/27 08:44:03 PM | Epoch: 31/89---Train:97.182----Test: 90.190\n",
            "\n",
            "INFO:gal:Epoch: 31/89---Train:97.182----Test: 90.190\n",
            "\n",
            "09/27 08:44:34 PM | Epoch: 32/89---Train:97.374----Test: 90.660\n",
            "\n",
            "09/27 08:44:34 PM | Epoch: 32/89---Train:97.374----Test: 90.660\n",
            "\n",
            "INFO:gal:Epoch: 32/89---Train:97.374----Test: 90.660\n",
            "\n",
            "09/27 08:45:06 PM | Epoch: 33/89---Train:97.370----Test: 90.600\n",
            "\n",
            "09/27 08:45:06 PM | Epoch: 33/89---Train:97.370----Test: 90.600\n",
            "\n",
            "INFO:gal:Epoch: 33/89---Train:97.370----Test: 90.600\n",
            "\n",
            "09/27 08:45:38 PM | Epoch: 34/89---Train:97.176----Test: 91.440\n",
            "\n",
            "09/27 08:45:38 PM | Epoch: 34/89---Train:97.176----Test: 91.440\n",
            "\n",
            "INFO:gal:Epoch: 34/89---Train:97.176----Test: 91.440\n",
            "\n",
            "09/27 08:46:09 PM | Epoch: 35/89---Train:97.168----Test: 90.870\n",
            "\n",
            "09/27 08:46:09 PM | Epoch: 35/89---Train:97.168----Test: 90.870\n",
            "\n",
            "INFO:gal:Epoch: 35/89---Train:97.168----Test: 90.870\n",
            "\n",
            "09/27 08:46:42 PM | Epoch: 36/89---Train:97.240----Test: 89.990\n",
            "\n",
            "09/27 08:46:42 PM | Epoch: 36/89---Train:97.240----Test: 89.990\n",
            "\n",
            "INFO:gal:Epoch: 36/89---Train:97.240----Test: 89.990\n",
            "\n",
            "09/27 08:47:14 PM | Epoch: 37/89---Train:97.450----Test: 89.920\n",
            "\n",
            "09/27 08:47:14 PM | Epoch: 37/89---Train:97.450----Test: 89.920\n",
            "\n",
            "INFO:gal:Epoch: 37/89---Train:97.450----Test: 89.920\n",
            "\n",
            "09/27 08:47:45 PM | Epoch: 38/89---Train:97.344----Test: 90.960\n",
            "\n",
            "09/27 08:47:45 PM | Epoch: 38/89---Train:97.344----Test: 90.960\n",
            "\n",
            "INFO:gal:Epoch: 38/89---Train:97.344----Test: 90.960\n",
            "\n",
            "09/27 08:48:17 PM | Epoch: 39/89---Train:97.298----Test: 91.040\n",
            "\n",
            "09/27 08:48:17 PM | Epoch: 39/89---Train:97.298----Test: 91.040\n",
            "\n",
            "INFO:gal:Epoch: 39/89---Train:97.298----Test: 91.040\n",
            "\n",
            "09/27 08:48:48 PM | Epoch: 40/89---Train:98.968----Test: 92.990\n",
            "\n",
            "09/27 08:48:48 PM | Epoch: 40/89---Train:98.968----Test: 92.990\n",
            "\n",
            "INFO:gal:Epoch: 40/89---Train:98.968----Test: 92.990\n",
            "\n",
            "09/27 08:49:21 PM | Epoch: 41/89---Train:99.370----Test: 93.340\n",
            "\n",
            "09/27 08:49:21 PM | Epoch: 41/89---Train:99.370----Test: 93.340\n",
            "\n",
            "INFO:gal:Epoch: 41/89---Train:99.370----Test: 93.340\n",
            "\n",
            "09/27 08:49:52 PM | Epoch: 42/89---Train:99.530----Test: 93.310\n",
            "\n",
            "09/27 08:49:52 PM | Epoch: 42/89---Train:99.530----Test: 93.310\n",
            "\n",
            "INFO:gal:Epoch: 42/89---Train:99.530----Test: 93.310\n",
            "\n",
            "09/27 08:50:24 PM | Epoch: 43/89---Train:99.598----Test: 93.410\n",
            "\n",
            "09/27 08:50:24 PM | Epoch: 43/89---Train:99.598----Test: 93.410\n",
            "\n",
            "INFO:gal:Epoch: 43/89---Train:99.598----Test: 93.410\n",
            "\n",
            "09/27 08:50:55 PM | Epoch: 44/89---Train:99.644----Test: 93.790\n",
            "\n",
            "09/27 08:50:55 PM | Epoch: 44/89---Train:99.644----Test: 93.790\n",
            "\n",
            "INFO:gal:Epoch: 44/89---Train:99.644----Test: 93.790\n",
            "\n",
            "09/27 08:51:27 PM | Epoch: 45/89---Train:99.654----Test: 93.610\n",
            "\n",
            "09/27 08:51:27 PM | Epoch: 45/89---Train:99.654----Test: 93.610\n",
            "\n",
            "INFO:gal:Epoch: 45/89---Train:99.654----Test: 93.610\n",
            "\n",
            "09/27 08:51:59 PM | Epoch: 46/89---Train:99.732----Test: 93.720\n",
            "\n",
            "09/27 08:51:59 PM | Epoch: 46/89---Train:99.732----Test: 93.720\n",
            "\n",
            "INFO:gal:Epoch: 46/89---Train:99.732----Test: 93.720\n",
            "\n",
            "09/27 08:52:31 PM | Epoch: 47/89---Train:99.748----Test: 93.770\n",
            "\n",
            "09/27 08:52:31 PM | Epoch: 47/89---Train:99.748----Test: 93.770\n",
            "\n",
            "INFO:gal:Epoch: 47/89---Train:99.748----Test: 93.770\n",
            "\n",
            "09/27 08:53:03 PM | Epoch: 48/89---Train:99.814----Test: 93.650\n",
            "\n",
            "09/27 08:53:03 PM | Epoch: 48/89---Train:99.814----Test: 93.650\n",
            "\n",
            "INFO:gal:Epoch: 48/89---Train:99.814----Test: 93.650\n",
            "\n",
            "09/27 08:53:35 PM | Epoch: 49/89---Train:99.766----Test: 93.820\n",
            "\n",
            "09/27 08:53:35 PM | Epoch: 49/89---Train:99.766----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 49/89---Train:99.766----Test: 93.820\n",
            "\n",
            "09/27 08:54:07 PM | Epoch: 50/89---Train:99.826----Test: 93.820\n",
            "\n",
            "09/27 08:54:07 PM | Epoch: 50/89---Train:99.826----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 50/89---Train:99.826----Test: 93.820\n",
            "\n",
            "09/27 08:54:40 PM | Epoch: 51/89---Train:99.862----Test: 93.740\n",
            "\n",
            "09/27 08:54:40 PM | Epoch: 51/89---Train:99.862----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 51/89---Train:99.862----Test: 93.740\n",
            "\n",
            "09/27 08:55:12 PM | Epoch: 52/89---Train:99.860----Test: 93.980\n",
            "\n",
            "09/27 08:55:12 PM | Epoch: 52/89---Train:99.860----Test: 93.980\n",
            "\n",
            "INFO:gal:Epoch: 52/89---Train:99.860----Test: 93.980\n",
            "\n",
            "09/27 08:55:44 PM | Epoch: 53/89---Train:99.846----Test: 93.830\n",
            "\n",
            "09/27 08:55:44 PM | Epoch: 53/89---Train:99.846----Test: 93.830\n",
            "\n",
            "INFO:gal:Epoch: 53/89---Train:99.846----Test: 93.830\n",
            "\n",
            "09/27 08:56:16 PM | Epoch: 54/89---Train:99.868----Test: 93.980\n",
            "\n",
            "09/27 08:56:16 PM | Epoch: 54/89---Train:99.868----Test: 93.980\n",
            "\n",
            "INFO:gal:Epoch: 54/89---Train:99.868----Test: 93.980\n",
            "\n",
            "09/27 08:56:48 PM | Epoch: 55/89---Train:99.870----Test: 93.880\n",
            "\n",
            "09/27 08:56:48 PM | Epoch: 55/89---Train:99.870----Test: 93.880\n",
            "\n",
            "INFO:gal:Epoch: 55/89---Train:99.870----Test: 93.880\n",
            "\n",
            "09/27 08:57:20 PM | Epoch: 56/89---Train:99.880----Test: 94.030\n",
            "\n",
            "09/27 08:57:20 PM | Epoch: 56/89---Train:99.880----Test: 94.030\n",
            "\n",
            "INFO:gal:Epoch: 56/89---Train:99.880----Test: 94.030\n",
            "\n",
            "09/27 08:57:52 PM | Epoch: 57/89---Train:99.902----Test: 93.900\n",
            "\n",
            "09/27 08:57:52 PM | Epoch: 57/89---Train:99.902----Test: 93.900\n",
            "\n",
            "INFO:gal:Epoch: 57/89---Train:99.902----Test: 93.900\n",
            "\n",
            "09/27 08:58:24 PM | Epoch: 58/89---Train:99.908----Test: 94.000\n",
            "\n",
            "09/27 08:58:24 PM | Epoch: 58/89---Train:99.908----Test: 94.000\n",
            "\n",
            "INFO:gal:Epoch: 58/89---Train:99.908----Test: 94.000\n",
            "\n",
            "09/27 08:58:56 PM | Epoch: 59/89---Train:99.896----Test: 93.880\n",
            "\n",
            "09/27 08:58:56 PM | Epoch: 59/89---Train:99.896----Test: 93.880\n",
            "\n",
            "INFO:gal:Epoch: 59/89---Train:99.896----Test: 93.880\n",
            "\n",
            "09/27 08:59:28 PM | Epoch: 60/89---Train:99.908----Test: 93.740\n",
            "\n",
            "09/27 08:59:28 PM | Epoch: 60/89---Train:99.908----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 60/89---Train:99.908----Test: 93.740\n",
            "\n",
            "09/27 09:00:00 PM | Epoch: 61/89---Train:99.902----Test: 94.100\n",
            "\n",
            "09/27 09:00:00 PM | Epoch: 61/89---Train:99.902----Test: 94.100\n",
            "\n",
            "INFO:gal:Epoch: 61/89---Train:99.902----Test: 94.100\n",
            "\n",
            "09/27 09:00:32 PM | Epoch: 62/89---Train:99.924----Test: 93.980\n",
            "\n",
            "09/27 09:00:32 PM | Epoch: 62/89---Train:99.924----Test: 93.980\n",
            "\n",
            "INFO:gal:Epoch: 62/89---Train:99.924----Test: 93.980\n",
            "\n",
            "09/27 09:01:04 PM | Epoch: 63/89---Train:99.942----Test: 93.900\n",
            "\n",
            "09/27 09:01:04 PM | Epoch: 63/89---Train:99.942----Test: 93.900\n",
            "\n",
            "INFO:gal:Epoch: 63/89---Train:99.942----Test: 93.900\n",
            "\n",
            "09/27 09:01:36 PM | Epoch: 64/89---Train:99.898----Test: 93.840\n",
            "\n",
            "09/27 09:01:36 PM | Epoch: 64/89---Train:99.898----Test: 93.840\n",
            "\n",
            "INFO:gal:Epoch: 64/89---Train:99.898----Test: 93.840\n",
            "\n",
            "09/27 09:02:08 PM | Epoch: 65/89---Train:99.916----Test: 94.010\n",
            "\n",
            "09/27 09:02:08 PM | Epoch: 65/89---Train:99.916----Test: 94.010\n",
            "\n",
            "INFO:gal:Epoch: 65/89---Train:99.916----Test: 94.010\n",
            "\n",
            "09/27 09:02:41 PM | Epoch: 66/89---Train:99.890----Test: 93.980\n",
            "\n",
            "09/27 09:02:41 PM | Epoch: 66/89---Train:99.890----Test: 93.980\n",
            "\n",
            "INFO:gal:Epoch: 66/89---Train:99.890----Test: 93.980\n",
            "\n",
            "09/27 09:03:13 PM | Epoch: 67/89---Train:99.942----Test: 94.050\n",
            "\n",
            "09/27 09:03:13 PM | Epoch: 67/89---Train:99.942----Test: 94.050\n",
            "\n",
            "INFO:gal:Epoch: 67/89---Train:99.942----Test: 94.050\n",
            "\n",
            "09/27 09:03:45 PM | Epoch: 68/89---Train:99.918----Test: 94.000\n",
            "\n",
            "09/27 09:03:45 PM | Epoch: 68/89---Train:99.918----Test: 94.000\n",
            "\n",
            "INFO:gal:Epoch: 68/89---Train:99.918----Test: 94.000\n",
            "\n",
            "09/27 09:04:17 PM | Epoch: 69/89---Train:99.932----Test: 93.990\n",
            "\n",
            "09/27 09:04:17 PM | Epoch: 69/89---Train:99.932----Test: 93.990\n",
            "\n",
            "INFO:gal:Epoch: 69/89---Train:99.932----Test: 93.990\n",
            "\n",
            "09/27 09:04:49 PM | Epoch: 70/89---Train:99.924----Test: 94.030\n",
            "\n",
            "09/27 09:04:49 PM | Epoch: 70/89---Train:99.924----Test: 94.030\n",
            "\n",
            "INFO:gal:Epoch: 70/89---Train:99.924----Test: 94.030\n",
            "\n",
            "09/27 09:05:22 PM | Epoch: 71/89---Train:99.956----Test: 93.970\n",
            "\n",
            "09/27 09:05:22 PM | Epoch: 71/89---Train:99.956----Test: 93.970\n",
            "\n",
            "INFO:gal:Epoch: 71/89---Train:99.956----Test: 93.970\n",
            "\n",
            "09/27 09:05:54 PM | Epoch: 72/89---Train:99.948----Test: 94.070\n",
            "\n",
            "09/27 09:05:54 PM | Epoch: 72/89---Train:99.948----Test: 94.070\n",
            "\n",
            "INFO:gal:Epoch: 72/89---Train:99.948----Test: 94.070\n",
            "\n",
            "09/27 09:06:26 PM | Epoch: 73/89---Train:99.958----Test: 94.020\n",
            "\n",
            "09/27 09:06:26 PM | Epoch: 73/89---Train:99.958----Test: 94.020\n",
            "\n",
            "INFO:gal:Epoch: 73/89---Train:99.958----Test: 94.020\n",
            "\n",
            "09/27 09:06:58 PM | Epoch: 74/89---Train:99.938----Test: 94.050\n",
            "\n",
            "09/27 09:06:58 PM | Epoch: 74/89---Train:99.938----Test: 94.050\n",
            "\n",
            "INFO:gal:Epoch: 74/89---Train:99.938----Test: 94.050\n",
            "\n",
            "09/27 09:07:30 PM | Epoch: 75/89---Train:99.926----Test: 93.930\n",
            "\n",
            "09/27 09:07:30 PM | Epoch: 75/89---Train:99.926----Test: 93.930\n",
            "\n",
            "INFO:gal:Epoch: 75/89---Train:99.926----Test: 93.930\n",
            "\n",
            "09/27 09:08:02 PM | Epoch: 76/89---Train:99.948----Test: 94.000\n",
            "\n",
            "09/27 09:08:02 PM | Epoch: 76/89---Train:99.948----Test: 94.000\n",
            "\n",
            "INFO:gal:Epoch: 76/89---Train:99.948----Test: 94.000\n",
            "\n",
            "09/27 09:08:34 PM | Epoch: 77/89---Train:99.946----Test: 94.070\n",
            "\n",
            "09/27 09:08:34 PM | Epoch: 77/89---Train:99.946----Test: 94.070\n",
            "\n",
            "INFO:gal:Epoch: 77/89---Train:99.946----Test: 94.070\n",
            "\n",
            "09/27 09:09:06 PM | Epoch: 78/89---Train:99.948----Test: 94.030\n",
            "\n",
            "09/27 09:09:06 PM | Epoch: 78/89---Train:99.948----Test: 94.030\n",
            "\n",
            "INFO:gal:Epoch: 78/89---Train:99.948----Test: 94.030\n",
            "\n",
            "09/27 09:09:38 PM | Epoch: 79/89---Train:99.940----Test: 94.010\n",
            "\n",
            "09/27 09:09:38 PM | Epoch: 79/89---Train:99.940----Test: 94.010\n",
            "\n",
            "INFO:gal:Epoch: 79/89---Train:99.940----Test: 94.010\n",
            "\n",
            "09/27 09:10:11 PM | Epoch: 80/89---Train:99.968----Test: 94.000\n",
            "\n",
            "09/27 09:10:11 PM | Epoch: 80/89---Train:99.968----Test: 94.000\n",
            "\n",
            "INFO:gal:Epoch: 80/89---Train:99.968----Test: 94.000\n",
            "\n",
            "09/27 09:10:43 PM | Epoch: 81/89---Train:99.962----Test: 94.110\n",
            "\n",
            "09/27 09:10:43 PM | Epoch: 81/89---Train:99.962----Test: 94.110\n",
            "\n",
            "INFO:gal:Epoch: 81/89---Train:99.962----Test: 94.110\n",
            "\n",
            "09/27 09:11:15 PM | Epoch: 82/89---Train:99.952----Test: 94.010\n",
            "\n",
            "09/27 09:11:15 PM | Epoch: 82/89---Train:99.952----Test: 94.010\n",
            "\n",
            "INFO:gal:Epoch: 82/89---Train:99.952----Test: 94.010\n",
            "\n",
            "09/27 09:11:47 PM | Epoch: 83/89---Train:99.952----Test: 94.100\n",
            "\n",
            "09/27 09:11:47 PM | Epoch: 83/89---Train:99.952----Test: 94.100\n",
            "\n",
            "INFO:gal:Epoch: 83/89---Train:99.952----Test: 94.100\n",
            "\n",
            "09/27 09:12:19 PM | Epoch: 84/89---Train:99.958----Test: 94.130\n",
            "\n",
            "09/27 09:12:19 PM | Epoch: 84/89---Train:99.958----Test: 94.130\n",
            "\n",
            "INFO:gal:Epoch: 84/89---Train:99.958----Test: 94.130\n",
            "\n",
            "09/27 09:12:51 PM | Epoch: 85/89---Train:99.962----Test: 94.070\n",
            "\n",
            "09/27 09:12:51 PM | Epoch: 85/89---Train:99.962----Test: 94.070\n",
            "\n",
            "INFO:gal:Epoch: 85/89---Train:99.962----Test: 94.070\n",
            "\n",
            "09/27 09:13:23 PM | Epoch: 86/89---Train:99.964----Test: 94.070\n",
            "\n",
            "09/27 09:13:23 PM | Epoch: 86/89---Train:99.964----Test: 94.070\n",
            "\n",
            "INFO:gal:Epoch: 86/89---Train:99.964----Test: 94.070\n",
            "\n",
            "09/27 09:13:55 PM | Epoch: 87/89---Train:99.956----Test: 94.010\n",
            "\n",
            "09/27 09:13:55 PM | Epoch: 87/89---Train:99.956----Test: 94.010\n",
            "\n",
            "INFO:gal:Epoch: 87/89---Train:99.956----Test: 94.010\n",
            "\n",
            "09/27 09:14:27 PM | Epoch: 88/89---Train:99.954----Test: 94.050\n",
            "\n",
            "09/27 09:14:27 PM | Epoch: 88/89---Train:99.954----Test: 94.050\n",
            "\n",
            "INFO:gal:Epoch: 88/89---Train:99.954----Test: 94.050\n",
            "\n",
            "09/27 09:14:59 PM | Epoch: 89/89---Train:99.944----Test: 93.990\n",
            "\n",
            "09/27 09:14:59 PM | Epoch: 89/89---Train:99.944----Test: 93.990\n",
            "\n",
            "INFO:gal:Epoch: 89/89---Train:99.944----Test: 93.990\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 09:19:05 PM | [33, 55, 125, 128, 256, 256, 256, 387, 250, 231, 265, 271, 271]\n",
            "09/27 09:19:05 PM | [33, 55, 125, 128, 256, 256, 256, 387, 250, 231, 265, 271, 271]\n",
            "INFO:gal:[33, 55, 125, 128, 256, 256, 256, 387, 250, 231, 265, 271, 271]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new-model starts....for  90  epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 09:19:33 PM | Epoch: 0/89---Train:96.082----Test: 88.960\n",
            "\n",
            "09/27 09:19:33 PM | Epoch: 0/89---Train:96.082----Test: 88.960\n",
            "\n",
            "INFO:gal:Epoch: 0/89---Train:96.082----Test: 88.960\n",
            "\n",
            "09/27 09:20:01 PM | Epoch: 1/89---Train:96.272----Test: 88.200\n",
            "\n",
            "09/27 09:20:01 PM | Epoch: 1/89---Train:96.272----Test: 88.200\n",
            "\n",
            "INFO:gal:Epoch: 1/89---Train:96.272----Test: 88.200\n",
            "\n",
            "09/27 09:20:31 PM | Epoch: 2/89---Train:96.346----Test: 89.160\n",
            "\n",
            "09/27 09:20:31 PM | Epoch: 2/89---Train:96.346----Test: 89.160\n",
            "\n",
            "INFO:gal:Epoch: 2/89---Train:96.346----Test: 89.160\n",
            "\n",
            "09/27 09:20:59 PM | Epoch: 3/89---Train:96.712----Test: 90.060\n",
            "\n",
            "09/27 09:20:59 PM | Epoch: 3/89---Train:96.712----Test: 90.060\n",
            "\n",
            "INFO:gal:Epoch: 3/89---Train:96.712----Test: 90.060\n",
            "\n",
            "09/27 09:21:28 PM | Epoch: 4/89---Train:96.542----Test: 90.320\n",
            "\n",
            "09/27 09:21:28 PM | Epoch: 4/89---Train:96.542----Test: 90.320\n",
            "\n",
            "INFO:gal:Epoch: 4/89---Train:96.542----Test: 90.320\n",
            "\n",
            "09/27 09:21:57 PM | Epoch: 5/89---Train:96.748----Test: 90.570\n",
            "\n",
            "09/27 09:21:57 PM | Epoch: 5/89---Train:96.748----Test: 90.570\n",
            "\n",
            "INFO:gal:Epoch: 5/89---Train:96.748----Test: 90.570\n",
            "\n",
            "09/27 09:22:26 PM | Epoch: 6/89---Train:96.902----Test: 89.960\n",
            "\n",
            "09/27 09:22:26 PM | Epoch: 6/89---Train:96.902----Test: 89.960\n",
            "\n",
            "INFO:gal:Epoch: 6/89---Train:96.902----Test: 89.960\n",
            "\n",
            "09/27 09:22:56 PM | Epoch: 7/89---Train:96.942----Test: 90.410\n",
            "\n",
            "09/27 09:22:56 PM | Epoch: 7/89---Train:96.942----Test: 90.410\n",
            "\n",
            "INFO:gal:Epoch: 7/89---Train:96.942----Test: 90.410\n",
            "\n",
            "09/27 09:23:25 PM | Epoch: 8/89---Train:97.024----Test: 91.160\n",
            "\n",
            "09/27 09:23:25 PM | Epoch: 8/89---Train:97.024----Test: 91.160\n",
            "\n",
            "INFO:gal:Epoch: 8/89---Train:97.024----Test: 91.160\n",
            "\n",
            "09/27 09:23:54 PM | Epoch: 9/89---Train:97.016----Test: 90.840\n",
            "\n",
            "09/27 09:23:54 PM | Epoch: 9/89---Train:97.016----Test: 90.840\n",
            "\n",
            "INFO:gal:Epoch: 9/89---Train:97.016----Test: 90.840\n",
            "\n",
            "09/27 09:24:23 PM | Epoch: 10/89---Train:97.058----Test: 91.120\n",
            "\n",
            "09/27 09:24:23 PM | Epoch: 10/89---Train:97.058----Test: 91.120\n",
            "\n",
            "INFO:gal:Epoch: 10/89---Train:97.058----Test: 91.120\n",
            "\n",
            "09/27 09:24:52 PM | Epoch: 11/89---Train:97.314----Test: 89.630\n",
            "\n",
            "09/27 09:24:52 PM | Epoch: 11/89---Train:97.314----Test: 89.630\n",
            "\n",
            "INFO:gal:Epoch: 11/89---Train:97.314----Test: 89.630\n",
            "\n",
            "09/27 09:25:22 PM | Epoch: 12/89---Train:97.030----Test: 90.750\n",
            "\n",
            "09/27 09:25:22 PM | Epoch: 12/89---Train:97.030----Test: 90.750\n",
            "\n",
            "INFO:gal:Epoch: 12/89---Train:97.030----Test: 90.750\n",
            "\n",
            "09/27 09:25:51 PM | Epoch: 13/89---Train:97.372----Test: 90.350\n",
            "\n",
            "09/27 09:25:51 PM | Epoch: 13/89---Train:97.372----Test: 90.350\n",
            "\n",
            "INFO:gal:Epoch: 13/89---Train:97.372----Test: 90.350\n",
            "\n",
            "09/27 09:26:20 PM | Epoch: 14/89---Train:97.236----Test: 89.990\n",
            "\n",
            "09/27 09:26:20 PM | Epoch: 14/89---Train:97.236----Test: 89.990\n",
            "\n",
            "INFO:gal:Epoch: 14/89---Train:97.236----Test: 89.990\n",
            "\n",
            "09/27 09:26:49 PM | Epoch: 15/89---Train:97.080----Test: 91.150\n",
            "\n",
            "09/27 09:26:49 PM | Epoch: 15/89---Train:97.080----Test: 91.150\n",
            "\n",
            "INFO:gal:Epoch: 15/89---Train:97.080----Test: 91.150\n",
            "\n",
            "09/27 09:27:18 PM | Epoch: 16/89---Train:97.334----Test: 90.790\n",
            "\n",
            "09/27 09:27:18 PM | Epoch: 16/89---Train:97.334----Test: 90.790\n",
            "\n",
            "INFO:gal:Epoch: 16/89---Train:97.334----Test: 90.790\n",
            "\n",
            "09/27 09:27:47 PM | Epoch: 17/89---Train:97.328----Test: 89.730\n",
            "\n",
            "09/27 09:27:47 PM | Epoch: 17/89---Train:97.328----Test: 89.730\n",
            "\n",
            "INFO:gal:Epoch: 17/89---Train:97.328----Test: 89.730\n",
            "\n",
            "09/27 09:28:18 PM | Epoch: 18/89---Train:97.024----Test: 90.380\n",
            "\n",
            "09/27 09:28:18 PM | Epoch: 18/89---Train:97.024----Test: 90.380\n",
            "\n",
            "INFO:gal:Epoch: 18/89---Train:97.024----Test: 90.380\n",
            "\n",
            "09/27 09:28:47 PM | Epoch: 19/89---Train:97.284----Test: 90.240\n",
            "\n",
            "09/27 09:28:47 PM | Epoch: 19/89---Train:97.284----Test: 90.240\n",
            "\n",
            "INFO:gal:Epoch: 19/89---Train:97.284----Test: 90.240\n",
            "\n",
            "09/27 09:29:16 PM | Epoch: 20/89---Train:97.266----Test: 90.920\n",
            "\n",
            "09/27 09:29:16 PM | Epoch: 20/89---Train:97.266----Test: 90.920\n",
            "\n",
            "INFO:gal:Epoch: 20/89---Train:97.266----Test: 90.920\n",
            "\n",
            "09/27 09:29:44 PM | Epoch: 21/89---Train:97.398----Test: 90.730\n",
            "\n",
            "09/27 09:29:44 PM | Epoch: 21/89---Train:97.398----Test: 90.730\n",
            "\n",
            "INFO:gal:Epoch: 21/89---Train:97.398----Test: 90.730\n",
            "\n",
            "09/27 09:30:13 PM | Epoch: 22/89---Train:97.260----Test: 88.580\n",
            "\n",
            "09/27 09:30:13 PM | Epoch: 22/89---Train:97.260----Test: 88.580\n",
            "\n",
            "INFO:gal:Epoch: 22/89---Train:97.260----Test: 88.580\n",
            "\n",
            "09/27 09:30:43 PM | Epoch: 23/89---Train:97.184----Test: 90.150\n",
            "\n",
            "09/27 09:30:43 PM | Epoch: 23/89---Train:97.184----Test: 90.150\n",
            "\n",
            "INFO:gal:Epoch: 23/89---Train:97.184----Test: 90.150\n",
            "\n",
            "09/27 09:31:12 PM | Epoch: 24/89---Train:97.238----Test: 90.210\n",
            "\n",
            "09/27 09:31:12 PM | Epoch: 24/89---Train:97.238----Test: 90.210\n",
            "\n",
            "INFO:gal:Epoch: 24/89---Train:97.238----Test: 90.210\n",
            "\n",
            "09/27 09:31:40 PM | Epoch: 25/89---Train:97.622----Test: 91.170\n",
            "\n",
            "09/27 09:31:40 PM | Epoch: 25/89---Train:97.622----Test: 91.170\n",
            "\n",
            "INFO:gal:Epoch: 25/89---Train:97.622----Test: 91.170\n",
            "\n",
            "09/27 09:32:09 PM | Epoch: 26/89---Train:97.418----Test: 91.020\n",
            "\n",
            "09/27 09:32:09 PM | Epoch: 26/89---Train:97.418----Test: 91.020\n",
            "\n",
            "INFO:gal:Epoch: 26/89---Train:97.418----Test: 91.020\n",
            "\n",
            "09/27 09:32:38 PM | Epoch: 27/89---Train:97.356----Test: 91.120\n",
            "\n",
            "09/27 09:32:38 PM | Epoch: 27/89---Train:97.356----Test: 91.120\n",
            "\n",
            "INFO:gal:Epoch: 27/89---Train:97.356----Test: 91.120\n",
            "\n",
            "09/27 09:33:06 PM | Epoch: 28/89---Train:97.314----Test: 90.680\n",
            "\n",
            "09/27 09:33:06 PM | Epoch: 28/89---Train:97.314----Test: 90.680\n",
            "\n",
            "INFO:gal:Epoch: 28/89---Train:97.314----Test: 90.680\n",
            "\n",
            "09/27 09:33:36 PM | Epoch: 29/89---Train:97.284----Test: 90.420\n",
            "\n",
            "09/27 09:33:36 PM | Epoch: 29/89---Train:97.284----Test: 90.420\n",
            "\n",
            "INFO:gal:Epoch: 29/89---Train:97.284----Test: 90.420\n",
            "\n",
            "09/27 09:34:05 PM | Epoch: 30/89---Train:97.272----Test: 89.820\n",
            "\n",
            "09/27 09:34:05 PM | Epoch: 30/89---Train:97.272----Test: 89.820\n",
            "\n",
            "INFO:gal:Epoch: 30/89---Train:97.272----Test: 89.820\n",
            "\n",
            "09/27 09:34:33 PM | Epoch: 31/89---Train:97.468----Test: 90.130\n",
            "\n",
            "09/27 09:34:33 PM | Epoch: 31/89---Train:97.468----Test: 90.130\n",
            "\n",
            "INFO:gal:Epoch: 31/89---Train:97.468----Test: 90.130\n",
            "\n",
            "09/27 09:35:02 PM | Epoch: 32/89---Train:97.340----Test: 89.970\n",
            "\n",
            "09/27 09:35:02 PM | Epoch: 32/89---Train:97.340----Test: 89.970\n",
            "\n",
            "INFO:gal:Epoch: 32/89---Train:97.340----Test: 89.970\n",
            "\n",
            "09/27 09:35:30 PM | Epoch: 33/89---Train:97.298----Test: 90.060\n",
            "\n",
            "09/27 09:35:30 PM | Epoch: 33/89---Train:97.298----Test: 90.060\n",
            "\n",
            "INFO:gal:Epoch: 33/89---Train:97.298----Test: 90.060\n",
            "\n",
            "09/27 09:36:00 PM | Epoch: 34/89---Train:97.428----Test: 90.380\n",
            "\n",
            "09/27 09:36:00 PM | Epoch: 34/89---Train:97.428----Test: 90.380\n",
            "\n",
            "INFO:gal:Epoch: 34/89---Train:97.428----Test: 90.380\n",
            "\n",
            "09/27 09:36:29 PM | Epoch: 35/89---Train:97.448----Test: 89.540\n",
            "\n",
            "09/27 09:36:29 PM | Epoch: 35/89---Train:97.448----Test: 89.540\n",
            "\n",
            "INFO:gal:Epoch: 35/89---Train:97.448----Test: 89.540\n",
            "\n",
            "09/27 09:36:57 PM | Epoch: 36/89---Train:97.372----Test: 90.360\n",
            "\n",
            "09/27 09:36:57 PM | Epoch: 36/89---Train:97.372----Test: 90.360\n",
            "\n",
            "INFO:gal:Epoch: 36/89---Train:97.372----Test: 90.360\n",
            "\n",
            "09/27 09:37:26 PM | Epoch: 37/89---Train:97.374----Test: 88.450\n",
            "\n",
            "09/27 09:37:26 PM | Epoch: 37/89---Train:97.374----Test: 88.450\n",
            "\n",
            "INFO:gal:Epoch: 37/89---Train:97.374----Test: 88.450\n",
            "\n",
            "09/27 09:37:54 PM | Epoch: 38/89---Train:97.394----Test: 88.970\n",
            "\n",
            "09/27 09:37:54 PM | Epoch: 38/89---Train:97.394----Test: 88.970\n",
            "\n",
            "INFO:gal:Epoch: 38/89---Train:97.394----Test: 88.970\n",
            "\n",
            "09/27 09:38:24 PM | Epoch: 39/89---Train:97.342----Test: 89.760\n",
            "\n",
            "09/27 09:38:24 PM | Epoch: 39/89---Train:97.342----Test: 89.760\n",
            "\n",
            "INFO:gal:Epoch: 39/89---Train:97.342----Test: 89.760\n",
            "\n",
            "09/27 09:38:53 PM | Epoch: 40/89---Train:98.754----Test: 93.090\n",
            "\n",
            "09/27 09:38:53 PM | Epoch: 40/89---Train:98.754----Test: 93.090\n",
            "\n",
            "INFO:gal:Epoch: 40/89---Train:98.754----Test: 93.090\n",
            "\n",
            "09/27 09:39:21 PM | Epoch: 41/89---Train:99.418----Test: 93.310\n",
            "\n",
            "09/27 09:39:21 PM | Epoch: 41/89---Train:99.418----Test: 93.310\n",
            "\n",
            "INFO:gal:Epoch: 41/89---Train:99.418----Test: 93.310\n",
            "\n",
            "09/27 09:39:50 PM | Epoch: 42/89---Train:99.594----Test: 93.430\n",
            "\n",
            "09/27 09:39:50 PM | Epoch: 42/89---Train:99.594----Test: 93.430\n",
            "\n",
            "INFO:gal:Epoch: 42/89---Train:99.594----Test: 93.430\n",
            "\n",
            "09/27 09:40:19 PM | Epoch: 43/89---Train:99.636----Test: 93.500\n",
            "\n",
            "09/27 09:40:19 PM | Epoch: 43/89---Train:99.636----Test: 93.500\n",
            "\n",
            "INFO:gal:Epoch: 43/89---Train:99.636----Test: 93.500\n",
            "\n",
            "09/27 09:40:47 PM | Epoch: 44/89---Train:99.706----Test: 93.590\n",
            "\n",
            "09/27 09:40:47 PM | Epoch: 44/89---Train:99.706----Test: 93.590\n",
            "\n",
            "INFO:gal:Epoch: 44/89---Train:99.706----Test: 93.590\n",
            "\n",
            "09/27 09:41:17 PM | Epoch: 45/89---Train:99.778----Test: 93.730\n",
            "\n",
            "09/27 09:41:17 PM | Epoch: 45/89---Train:99.778----Test: 93.730\n",
            "\n",
            "INFO:gal:Epoch: 45/89---Train:99.778----Test: 93.730\n",
            "\n",
            "09/27 09:41:46 PM | Epoch: 46/89---Train:99.798----Test: 93.500\n",
            "\n",
            "09/27 09:41:46 PM | Epoch: 46/89---Train:99.798----Test: 93.500\n",
            "\n",
            "INFO:gal:Epoch: 46/89---Train:99.798----Test: 93.500\n",
            "\n",
            "09/27 09:42:14 PM | Epoch: 47/89---Train:99.800----Test: 93.560\n",
            "\n",
            "09/27 09:42:14 PM | Epoch: 47/89---Train:99.800----Test: 93.560\n",
            "\n",
            "INFO:gal:Epoch: 47/89---Train:99.800----Test: 93.560\n",
            "\n",
            "09/27 09:42:43 PM | Epoch: 48/89---Train:99.826----Test: 93.610\n",
            "\n",
            "09/27 09:42:43 PM | Epoch: 48/89---Train:99.826----Test: 93.610\n",
            "\n",
            "INFO:gal:Epoch: 48/89---Train:99.826----Test: 93.610\n",
            "\n",
            "09/27 09:43:11 PM | Epoch: 49/89---Train:99.822----Test: 93.620\n",
            "\n",
            "09/27 09:43:11 PM | Epoch: 49/89---Train:99.822----Test: 93.620\n",
            "\n",
            "INFO:gal:Epoch: 49/89---Train:99.822----Test: 93.620\n",
            "\n",
            "09/27 09:43:41 PM | Epoch: 50/89---Train:99.876----Test: 93.840\n",
            "\n",
            "09/27 09:43:41 PM | Epoch: 50/89---Train:99.876----Test: 93.840\n",
            "\n",
            "INFO:gal:Epoch: 50/89---Train:99.876----Test: 93.840\n",
            "\n",
            "09/27 09:44:10 PM | Epoch: 51/89---Train:99.860----Test: 93.780\n",
            "\n",
            "09/27 09:44:10 PM | Epoch: 51/89---Train:99.860----Test: 93.780\n",
            "\n",
            "INFO:gal:Epoch: 51/89---Train:99.860----Test: 93.780\n",
            "\n",
            "09/27 09:44:38 PM | Epoch: 52/89---Train:99.858----Test: 93.760\n",
            "\n",
            "09/27 09:44:38 PM | Epoch: 52/89---Train:99.858----Test: 93.760\n",
            "\n",
            "INFO:gal:Epoch: 52/89---Train:99.858----Test: 93.760\n",
            "\n",
            "09/27 09:45:07 PM | Epoch: 53/89---Train:99.874----Test: 93.790\n",
            "\n",
            "09/27 09:45:07 PM | Epoch: 53/89---Train:99.874----Test: 93.790\n",
            "\n",
            "INFO:gal:Epoch: 53/89---Train:99.874----Test: 93.790\n",
            "\n",
            "09/27 09:45:35 PM | Epoch: 54/89---Train:99.876----Test: 93.880\n",
            "\n",
            "09/27 09:45:35 PM | Epoch: 54/89---Train:99.876----Test: 93.880\n",
            "\n",
            "INFO:gal:Epoch: 54/89---Train:99.876----Test: 93.880\n",
            "\n",
            "09/27 09:46:05 PM | Epoch: 55/89---Train:99.904----Test: 93.630\n",
            "\n",
            "09/27 09:46:05 PM | Epoch: 55/89---Train:99.904----Test: 93.630\n",
            "\n",
            "INFO:gal:Epoch: 55/89---Train:99.904----Test: 93.630\n",
            "\n",
            "09/27 09:46:34 PM | Epoch: 56/89---Train:99.890----Test: 93.680\n",
            "\n",
            "09/27 09:46:34 PM | Epoch: 56/89---Train:99.890----Test: 93.680\n",
            "\n",
            "INFO:gal:Epoch: 56/89---Train:99.890----Test: 93.680\n",
            "\n",
            "09/27 09:47:02 PM | Epoch: 57/89---Train:99.920----Test: 93.660\n",
            "\n",
            "09/27 09:47:02 PM | Epoch: 57/89---Train:99.920----Test: 93.660\n",
            "\n",
            "INFO:gal:Epoch: 57/89---Train:99.920----Test: 93.660\n",
            "\n",
            "09/27 09:47:31 PM | Epoch: 58/89---Train:99.886----Test: 93.540\n",
            "\n",
            "09/27 09:47:31 PM | Epoch: 58/89---Train:99.886----Test: 93.540\n",
            "\n",
            "INFO:gal:Epoch: 58/89---Train:99.886----Test: 93.540\n",
            "\n",
            "09/27 09:48:00 PM | Epoch: 59/89---Train:99.892----Test: 93.770\n",
            "\n",
            "09/27 09:48:00 PM | Epoch: 59/89---Train:99.892----Test: 93.770\n",
            "\n",
            "INFO:gal:Epoch: 59/89---Train:99.892----Test: 93.770\n",
            "\n",
            "09/27 09:48:28 PM | Epoch: 60/89---Train:99.924----Test: 93.740\n",
            "\n",
            "09/27 09:48:28 PM | Epoch: 60/89---Train:99.924----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 60/89---Train:99.924----Test: 93.740\n",
            "\n",
            "09/27 09:48:58 PM | Epoch: 61/89---Train:99.922----Test: 93.800\n",
            "\n",
            "09/27 09:48:58 PM | Epoch: 61/89---Train:99.922----Test: 93.800\n",
            "\n",
            "INFO:gal:Epoch: 61/89---Train:99.922----Test: 93.800\n",
            "\n",
            "09/27 09:49:26 PM | Epoch: 62/89---Train:99.906----Test: 93.820\n",
            "\n",
            "09/27 09:49:26 PM | Epoch: 62/89---Train:99.906----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 62/89---Train:99.906----Test: 93.820\n",
            "\n",
            "09/27 09:49:55 PM | Epoch: 63/89---Train:99.902----Test: 93.740\n",
            "\n",
            "09/27 09:49:55 PM | Epoch: 63/89---Train:99.902----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 63/89---Train:99.902----Test: 93.740\n",
            "\n",
            "09/27 09:50:24 PM | Epoch: 64/89---Train:99.928----Test: 93.700\n",
            "\n",
            "09/27 09:50:24 PM | Epoch: 64/89---Train:99.928----Test: 93.700\n",
            "\n",
            "INFO:gal:Epoch: 64/89---Train:99.928----Test: 93.700\n",
            "\n",
            "09/27 09:50:52 PM | Epoch: 65/89---Train:99.942----Test: 93.840\n",
            "\n",
            "09/27 09:50:52 PM | Epoch: 65/89---Train:99.942----Test: 93.840\n",
            "\n",
            "INFO:gal:Epoch: 65/89---Train:99.942----Test: 93.840\n",
            "\n",
            "09/27 09:51:22 PM | Epoch: 66/89---Train:99.936----Test: 93.770\n",
            "\n",
            "09/27 09:51:22 PM | Epoch: 66/89---Train:99.936----Test: 93.770\n",
            "\n",
            "INFO:gal:Epoch: 66/89---Train:99.936----Test: 93.770\n",
            "\n",
            "09/27 09:51:50 PM | Epoch: 67/89---Train:99.934----Test: 93.810\n",
            "\n",
            "09/27 09:51:50 PM | Epoch: 67/89---Train:99.934----Test: 93.810\n",
            "\n",
            "INFO:gal:Epoch: 67/89---Train:99.934----Test: 93.810\n",
            "\n",
            "09/27 09:52:19 PM | Epoch: 68/89---Train:99.930----Test: 93.710\n",
            "\n",
            "09/27 09:52:19 PM | Epoch: 68/89---Train:99.930----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 68/89---Train:99.930----Test: 93.710\n",
            "\n",
            "09/27 09:52:47 PM | Epoch: 69/89---Train:99.936----Test: 93.800\n",
            "\n",
            "09/27 09:52:47 PM | Epoch: 69/89---Train:99.936----Test: 93.800\n",
            "\n",
            "INFO:gal:Epoch: 69/89---Train:99.936----Test: 93.800\n",
            "\n",
            "09/27 09:53:16 PM | Epoch: 70/89---Train:99.948----Test: 93.770\n",
            "\n",
            "09/27 09:53:16 PM | Epoch: 70/89---Train:99.948----Test: 93.770\n",
            "\n",
            "INFO:gal:Epoch: 70/89---Train:99.948----Test: 93.770\n",
            "\n",
            "09/27 09:53:46 PM | Epoch: 71/89---Train:99.944----Test: 93.800\n",
            "\n",
            "09/27 09:53:46 PM | Epoch: 71/89---Train:99.944----Test: 93.800\n",
            "\n",
            "INFO:gal:Epoch: 71/89---Train:99.944----Test: 93.800\n",
            "\n",
            "09/27 09:54:14 PM | Epoch: 72/89---Train:99.966----Test: 93.740\n",
            "\n",
            "09/27 09:54:14 PM | Epoch: 72/89---Train:99.966----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 72/89---Train:99.966----Test: 93.740\n",
            "\n",
            "09/27 09:54:43 PM | Epoch: 73/89---Train:99.946----Test: 93.750\n",
            "\n",
            "09/27 09:54:43 PM | Epoch: 73/89---Train:99.946----Test: 93.750\n",
            "\n",
            "INFO:gal:Epoch: 73/89---Train:99.946----Test: 93.750\n",
            "\n",
            "09/27 09:55:11 PM | Epoch: 74/89---Train:99.954----Test: 93.760\n",
            "\n",
            "09/27 09:55:11 PM | Epoch: 74/89---Train:99.954----Test: 93.760\n",
            "\n",
            "INFO:gal:Epoch: 74/89---Train:99.954----Test: 93.760\n",
            "\n",
            "09/27 09:55:40 PM | Epoch: 75/89---Train:99.962----Test: 93.780\n",
            "\n",
            "09/27 09:55:40 PM | Epoch: 75/89---Train:99.962----Test: 93.780\n",
            "\n",
            "INFO:gal:Epoch: 75/89---Train:99.962----Test: 93.780\n",
            "\n",
            "09/27 09:56:10 PM | Epoch: 76/89---Train:99.944----Test: 93.730\n",
            "\n",
            "09/27 09:56:10 PM | Epoch: 76/89---Train:99.944----Test: 93.730\n",
            "\n",
            "INFO:gal:Epoch: 76/89---Train:99.944----Test: 93.730\n",
            "\n",
            "09/27 09:56:38 PM | Epoch: 77/89---Train:99.970----Test: 93.750\n",
            "\n",
            "09/27 09:56:38 PM | Epoch: 77/89---Train:99.970----Test: 93.750\n",
            "\n",
            "INFO:gal:Epoch: 77/89---Train:99.970----Test: 93.750\n",
            "\n",
            "09/27 09:57:07 PM | Epoch: 78/89---Train:99.938----Test: 93.820\n",
            "\n",
            "09/27 09:57:07 PM | Epoch: 78/89---Train:99.938----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 78/89---Train:99.938----Test: 93.820\n",
            "\n",
            "09/27 09:57:35 PM | Epoch: 79/89---Train:99.958----Test: 93.750\n",
            "\n",
            "09/27 09:57:35 PM | Epoch: 79/89---Train:99.958----Test: 93.750\n",
            "\n",
            "INFO:gal:Epoch: 79/89---Train:99.958----Test: 93.750\n",
            "\n",
            "09/27 09:58:04 PM | Epoch: 80/89---Train:99.942----Test: 93.890\n",
            "\n",
            "09/27 09:58:04 PM | Epoch: 80/89---Train:99.942----Test: 93.890\n",
            "\n",
            "INFO:gal:Epoch: 80/89---Train:99.942----Test: 93.890\n",
            "\n",
            "09/27 09:58:33 PM | Epoch: 81/89---Train:99.954----Test: 93.820\n",
            "\n",
            "09/27 09:58:33 PM | Epoch: 81/89---Train:99.954----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 81/89---Train:99.954----Test: 93.820\n",
            "\n",
            "09/27 09:59:02 PM | Epoch: 82/89---Train:99.956----Test: 93.870\n",
            "\n",
            "09/27 09:59:02 PM | Epoch: 82/89---Train:99.956----Test: 93.870\n",
            "\n",
            "INFO:gal:Epoch: 82/89---Train:99.956----Test: 93.870\n",
            "\n",
            "09/27 09:59:31 PM | Epoch: 83/89---Train:99.954----Test: 93.830\n",
            "\n",
            "09/27 09:59:31 PM | Epoch: 83/89---Train:99.954----Test: 93.830\n",
            "\n",
            "INFO:gal:Epoch: 83/89---Train:99.954----Test: 93.830\n",
            "\n",
            "09/27 10:00:00 PM | Epoch: 84/89---Train:99.948----Test: 93.900\n",
            "\n",
            "09/27 10:00:00 PM | Epoch: 84/89---Train:99.948----Test: 93.900\n",
            "\n",
            "INFO:gal:Epoch: 84/89---Train:99.948----Test: 93.900\n",
            "\n",
            "09/27 10:00:29 PM | Epoch: 85/89---Train:99.954----Test: 93.760\n",
            "\n",
            "09/27 10:00:29 PM | Epoch: 85/89---Train:99.954----Test: 93.760\n",
            "\n",
            "INFO:gal:Epoch: 85/89---Train:99.954----Test: 93.760\n",
            "\n",
            "09/27 10:00:57 PM | Epoch: 86/89---Train:99.948----Test: 93.720\n",
            "\n",
            "09/27 10:00:57 PM | Epoch: 86/89---Train:99.948----Test: 93.720\n",
            "\n",
            "INFO:gal:Epoch: 86/89---Train:99.948----Test: 93.720\n",
            "\n",
            "09/27 10:01:27 PM | Epoch: 87/89---Train:99.962----Test: 93.850\n",
            "\n",
            "09/27 10:01:27 PM | Epoch: 87/89---Train:99.962----Test: 93.850\n",
            "\n",
            "INFO:gal:Epoch: 87/89---Train:99.962----Test: 93.850\n",
            "\n",
            "09/27 10:01:56 PM | Epoch: 88/89---Train:99.970----Test: 93.820\n",
            "\n",
            "09/27 10:01:56 PM | Epoch: 88/89---Train:99.970----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 88/89---Train:99.970----Test: 93.820\n",
            "\n",
            "09/27 10:02:24 PM | Epoch: 89/89---Train:99.962----Test: 93.820\n",
            "\n",
            "09/27 10:02:24 PM | Epoch: 89/89---Train:99.962----Test: 93.820\n",
            "\n",
            "INFO:gal:Epoch: 89/89---Train:99.962----Test: 93.820\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 10:06:12 PM | [27, 54, 125, 128, 256, 256, 256, 371, 191, 151, 186, 193, 196]\n",
            "09/27 10:06:12 PM | [27, 54, 125, 128, 256, 256, 256, 371, 191, 151, 186, 193, 196]\n",
            "INFO:gal:[27, 54, 125, 128, 256, 256, 256, 371, 191, 151, 186, 193, 196]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new-model starts....for  90  epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 10:06:39 PM | Epoch: 0/89---Train:96.068----Test: 86.550\n",
            "\n",
            "09/27 10:06:39 PM | Epoch: 0/89---Train:96.068----Test: 86.550\n",
            "\n",
            "INFO:gal:Epoch: 0/89---Train:96.068----Test: 86.550\n",
            "\n",
            "09/27 10:07:06 PM | Epoch: 1/89---Train:96.248----Test: 87.570\n",
            "\n",
            "09/27 10:07:06 PM | Epoch: 1/89---Train:96.248----Test: 87.570\n",
            "\n",
            "INFO:gal:Epoch: 1/89---Train:96.248----Test: 87.570\n",
            "\n",
            "09/27 10:07:32 PM | Epoch: 2/89---Train:96.510----Test: 89.500\n",
            "\n",
            "09/27 10:07:32 PM | Epoch: 2/89---Train:96.510----Test: 89.500\n",
            "\n",
            "INFO:gal:Epoch: 2/89---Train:96.510----Test: 89.500\n",
            "\n",
            "09/27 10:07:59 PM | Epoch: 3/89---Train:96.510----Test: 90.060\n",
            "\n",
            "09/27 10:07:59 PM | Epoch: 3/89---Train:96.510----Test: 90.060\n",
            "\n",
            "INFO:gal:Epoch: 3/89---Train:96.510----Test: 90.060\n",
            "\n",
            "09/27 10:08:26 PM | Epoch: 4/89---Train:97.030----Test: 90.550\n",
            "\n",
            "09/27 10:08:26 PM | Epoch: 4/89---Train:97.030----Test: 90.550\n",
            "\n",
            "INFO:gal:Epoch: 4/89---Train:97.030----Test: 90.550\n",
            "\n",
            "09/27 10:08:54 PM | Epoch: 5/89---Train:96.890----Test: 90.260\n",
            "\n",
            "09/27 10:08:54 PM | Epoch: 5/89---Train:96.890----Test: 90.260\n",
            "\n",
            "INFO:gal:Epoch: 5/89---Train:96.890----Test: 90.260\n",
            "\n",
            "09/27 10:09:21 PM | Epoch: 6/89---Train:97.094----Test: 87.740\n",
            "\n",
            "09/27 10:09:21 PM | Epoch: 6/89---Train:97.094----Test: 87.740\n",
            "\n",
            "INFO:gal:Epoch: 6/89---Train:97.094----Test: 87.740\n",
            "\n",
            "09/27 10:09:48 PM | Epoch: 7/89---Train:97.018----Test: 89.880\n",
            "\n",
            "09/27 10:09:48 PM | Epoch: 7/89---Train:97.018----Test: 89.880\n",
            "\n",
            "INFO:gal:Epoch: 7/89---Train:97.018----Test: 89.880\n",
            "\n",
            "09/27 10:10:15 PM | Epoch: 8/89---Train:97.138----Test: 90.530\n",
            "\n",
            "09/27 10:10:15 PM | Epoch: 8/89---Train:97.138----Test: 90.530\n",
            "\n",
            "INFO:gal:Epoch: 8/89---Train:97.138----Test: 90.530\n",
            "\n",
            "09/27 10:10:42 PM | Epoch: 9/89---Train:97.118----Test: 90.600\n",
            "\n",
            "09/27 10:10:42 PM | Epoch: 9/89---Train:97.118----Test: 90.600\n",
            "\n",
            "INFO:gal:Epoch: 9/89---Train:97.118----Test: 90.600\n",
            "\n",
            "09/27 10:11:11 PM | Epoch: 10/89---Train:97.284----Test: 90.440\n",
            "\n",
            "09/27 10:11:11 PM | Epoch: 10/89---Train:97.284----Test: 90.440\n",
            "\n",
            "INFO:gal:Epoch: 10/89---Train:97.284----Test: 90.440\n",
            "\n",
            "09/27 10:11:38 PM | Epoch: 11/89---Train:97.288----Test: 89.840\n",
            "\n",
            "09/27 10:11:38 PM | Epoch: 11/89---Train:97.288----Test: 89.840\n",
            "\n",
            "INFO:gal:Epoch: 11/89---Train:97.288----Test: 89.840\n",
            "\n",
            "09/27 10:12:05 PM | Epoch: 12/89---Train:97.162----Test: 89.900\n",
            "\n",
            "09/27 10:12:05 PM | Epoch: 12/89---Train:97.162----Test: 89.900\n",
            "\n",
            "INFO:gal:Epoch: 12/89---Train:97.162----Test: 89.900\n",
            "\n",
            "09/27 10:12:32 PM | Epoch: 13/89---Train:97.254----Test: 90.230\n",
            "\n",
            "09/27 10:12:32 PM | Epoch: 13/89---Train:97.254----Test: 90.230\n",
            "\n",
            "INFO:gal:Epoch: 13/89---Train:97.254----Test: 90.230\n",
            "\n",
            "09/27 10:12:59 PM | Epoch: 14/89---Train:97.278----Test: 88.940\n",
            "\n",
            "09/27 10:12:59 PM | Epoch: 14/89---Train:97.278----Test: 88.940\n",
            "\n",
            "INFO:gal:Epoch: 14/89---Train:97.278----Test: 88.940\n",
            "\n",
            "09/27 10:13:28 PM | Epoch: 15/89---Train:97.388----Test: 90.030\n",
            "\n",
            "09/27 10:13:28 PM | Epoch: 15/89---Train:97.388----Test: 90.030\n",
            "\n",
            "INFO:gal:Epoch: 15/89---Train:97.388----Test: 90.030\n",
            "\n",
            "09/27 10:13:55 PM | Epoch: 16/89---Train:97.314----Test: 88.930\n",
            "\n",
            "09/27 10:13:55 PM | Epoch: 16/89---Train:97.314----Test: 88.930\n",
            "\n",
            "INFO:gal:Epoch: 16/89---Train:97.314----Test: 88.930\n",
            "\n",
            "09/27 10:14:22 PM | Epoch: 17/89---Train:97.468----Test: 89.860\n",
            "\n",
            "09/27 10:14:22 PM | Epoch: 17/89---Train:97.468----Test: 89.860\n",
            "\n",
            "INFO:gal:Epoch: 17/89---Train:97.468----Test: 89.860\n",
            "\n",
            "09/27 10:14:50 PM | Epoch: 18/89---Train:97.506----Test: 90.590\n",
            "\n",
            "09/27 10:14:50 PM | Epoch: 18/89---Train:97.506----Test: 90.590\n",
            "\n",
            "INFO:gal:Epoch: 18/89---Train:97.506----Test: 90.590\n",
            "\n",
            "09/27 10:15:17 PM | Epoch: 19/89---Train:97.356----Test: 90.530\n",
            "\n",
            "09/27 10:15:17 PM | Epoch: 19/89---Train:97.356----Test: 90.530\n",
            "\n",
            "INFO:gal:Epoch: 19/89---Train:97.356----Test: 90.530\n",
            "\n",
            "09/27 10:15:45 PM | Epoch: 20/89---Train:97.308----Test: 89.830\n",
            "\n",
            "09/27 10:15:45 PM | Epoch: 20/89---Train:97.308----Test: 89.830\n",
            "\n",
            "INFO:gal:Epoch: 20/89---Train:97.308----Test: 89.830\n",
            "\n",
            "09/27 10:16:13 PM | Epoch: 21/89---Train:97.458----Test: 90.880\n",
            "\n",
            "09/27 10:16:13 PM | Epoch: 21/89---Train:97.458----Test: 90.880\n",
            "\n",
            "INFO:gal:Epoch: 21/89---Train:97.458----Test: 90.880\n",
            "\n",
            "09/27 10:16:40 PM | Epoch: 22/89---Train:97.230----Test: 90.470\n",
            "\n",
            "09/27 10:16:40 PM | Epoch: 22/89---Train:97.230----Test: 90.470\n",
            "\n",
            "INFO:gal:Epoch: 22/89---Train:97.230----Test: 90.470\n",
            "\n",
            "09/27 10:17:07 PM | Epoch: 23/89---Train:97.364----Test: 89.980\n",
            "\n",
            "09/27 10:17:07 PM | Epoch: 23/89---Train:97.364----Test: 89.980\n",
            "\n",
            "INFO:gal:Epoch: 23/89---Train:97.364----Test: 89.980\n",
            "\n",
            "09/27 10:17:34 PM | Epoch: 24/89---Train:97.536----Test: 90.770\n",
            "\n",
            "09/27 10:17:34 PM | Epoch: 24/89---Train:97.536----Test: 90.770\n",
            "\n",
            "INFO:gal:Epoch: 24/89---Train:97.536----Test: 90.770\n",
            "\n",
            "09/27 10:18:03 PM | Epoch: 25/89---Train:97.382----Test: 89.910\n",
            "\n",
            "09/27 10:18:03 PM | Epoch: 25/89---Train:97.382----Test: 89.910\n",
            "\n",
            "INFO:gal:Epoch: 25/89---Train:97.382----Test: 89.910\n",
            "\n",
            "09/27 10:18:33 PM | Epoch: 26/89---Train:97.598----Test: 90.910\n",
            "\n",
            "09/27 10:18:33 PM | Epoch: 26/89---Train:97.598----Test: 90.910\n",
            "\n",
            "INFO:gal:Epoch: 26/89---Train:97.598----Test: 90.910\n",
            "\n",
            "09/27 10:19:00 PM | Epoch: 27/89---Train:97.458----Test: 90.060\n",
            "\n",
            "09/27 10:19:00 PM | Epoch: 27/89---Train:97.458----Test: 90.060\n",
            "\n",
            "INFO:gal:Epoch: 27/89---Train:97.458----Test: 90.060\n",
            "\n",
            "09/27 10:19:28 PM | Epoch: 28/89---Train:97.524----Test: 90.930\n",
            "\n",
            "09/27 10:19:28 PM | Epoch: 28/89---Train:97.524----Test: 90.930\n",
            "\n",
            "INFO:gal:Epoch: 28/89---Train:97.524----Test: 90.930\n",
            "\n",
            "09/27 10:19:55 PM | Epoch: 29/89---Train:97.242----Test: 89.970\n",
            "\n",
            "09/27 10:19:55 PM | Epoch: 29/89---Train:97.242----Test: 89.970\n",
            "\n",
            "INFO:gal:Epoch: 29/89---Train:97.242----Test: 89.970\n",
            "\n",
            "09/27 10:20:22 PM | Epoch: 30/89---Train:97.502----Test: 90.660\n",
            "\n",
            "09/27 10:20:22 PM | Epoch: 30/89---Train:97.502----Test: 90.660\n",
            "\n",
            "INFO:gal:Epoch: 30/89---Train:97.502----Test: 90.660\n",
            "\n",
            "09/27 10:20:50 PM | Epoch: 31/89---Train:97.344----Test: 90.480\n",
            "\n",
            "09/27 10:20:50 PM | Epoch: 31/89---Train:97.344----Test: 90.480\n",
            "\n",
            "INFO:gal:Epoch: 31/89---Train:97.344----Test: 90.480\n",
            "\n",
            "09/27 10:21:18 PM | Epoch: 32/89---Train:97.616----Test: 90.310\n",
            "\n",
            "09/27 10:21:18 PM | Epoch: 32/89---Train:97.616----Test: 90.310\n",
            "\n",
            "INFO:gal:Epoch: 32/89---Train:97.616----Test: 90.310\n",
            "\n",
            "09/27 10:21:45 PM | Epoch: 33/89---Train:97.146----Test: 91.380\n",
            "\n",
            "09/27 10:21:45 PM | Epoch: 33/89---Train:97.146----Test: 91.380\n",
            "\n",
            "INFO:gal:Epoch: 33/89---Train:97.146----Test: 91.380\n",
            "\n",
            "09/27 10:22:12 PM | Epoch: 34/89---Train:97.700----Test: 89.470\n",
            "\n",
            "09/27 10:22:12 PM | Epoch: 34/89---Train:97.700----Test: 89.470\n",
            "\n",
            "INFO:gal:Epoch: 34/89---Train:97.700----Test: 89.470\n",
            "\n",
            "09/27 10:22:39 PM | Epoch: 35/89---Train:97.342----Test: 89.690\n",
            "\n",
            "09/27 10:22:39 PM | Epoch: 35/89---Train:97.342----Test: 89.690\n",
            "\n",
            "INFO:gal:Epoch: 35/89---Train:97.342----Test: 89.690\n",
            "\n",
            "09/27 10:23:07 PM | Epoch: 36/89---Train:97.618----Test: 91.330\n",
            "\n",
            "09/27 10:23:07 PM | Epoch: 36/89---Train:97.618----Test: 91.330\n",
            "\n",
            "INFO:gal:Epoch: 36/89---Train:97.618----Test: 91.330\n",
            "\n",
            "09/27 10:23:35 PM | Epoch: 37/89---Train:97.350----Test: 90.560\n",
            "\n",
            "09/27 10:23:35 PM | Epoch: 37/89---Train:97.350----Test: 90.560\n",
            "\n",
            "INFO:gal:Epoch: 37/89---Train:97.350----Test: 90.560\n",
            "\n",
            "09/27 10:24:02 PM | Epoch: 38/89---Train:97.522----Test: 89.930\n",
            "\n",
            "09/27 10:24:02 PM | Epoch: 38/89---Train:97.522----Test: 89.930\n",
            "\n",
            "INFO:gal:Epoch: 38/89---Train:97.522----Test: 89.930\n",
            "\n",
            "09/27 10:24:29 PM | Epoch: 39/89---Train:97.510----Test: 90.590\n",
            "\n",
            "09/27 10:24:29 PM | Epoch: 39/89---Train:97.510----Test: 90.590\n",
            "\n",
            "INFO:gal:Epoch: 39/89---Train:97.510----Test: 90.590\n",
            "\n",
            "09/27 10:24:56 PM | Epoch: 40/89---Train:98.936----Test: 92.840\n",
            "\n",
            "09/27 10:24:56 PM | Epoch: 40/89---Train:98.936----Test: 92.840\n",
            "\n",
            "INFO:gal:Epoch: 40/89---Train:98.936----Test: 92.840\n",
            "\n",
            "09/27 10:25:25 PM | Epoch: 41/89---Train:99.434----Test: 93.070\n",
            "\n",
            "09/27 10:25:25 PM | Epoch: 41/89---Train:99.434----Test: 93.070\n",
            "\n",
            "INFO:gal:Epoch: 41/89---Train:99.434----Test: 93.070\n",
            "\n",
            "09/27 10:25:52 PM | Epoch: 42/89---Train:99.586----Test: 93.270\n",
            "\n",
            "09/27 10:25:52 PM | Epoch: 42/89---Train:99.586----Test: 93.270\n",
            "\n",
            "INFO:gal:Epoch: 42/89---Train:99.586----Test: 93.270\n",
            "\n",
            "09/27 10:26:19 PM | Epoch: 43/89---Train:99.674----Test: 93.370\n",
            "\n",
            "09/27 10:26:19 PM | Epoch: 43/89---Train:99.674----Test: 93.370\n",
            "\n",
            "INFO:gal:Epoch: 43/89---Train:99.674----Test: 93.370\n",
            "\n",
            "09/27 10:26:47 PM | Epoch: 44/89---Train:99.682----Test: 93.300\n",
            "\n",
            "09/27 10:26:47 PM | Epoch: 44/89---Train:99.682----Test: 93.300\n",
            "\n",
            "INFO:gal:Epoch: 44/89---Train:99.682----Test: 93.300\n",
            "\n",
            "09/27 10:27:14 PM | Epoch: 45/89---Train:99.748----Test: 93.530\n",
            "\n",
            "09/27 10:27:14 PM | Epoch: 45/89---Train:99.748----Test: 93.530\n",
            "\n",
            "INFO:gal:Epoch: 45/89---Train:99.748----Test: 93.530\n",
            "\n",
            "09/27 10:27:41 PM | Epoch: 46/89---Train:99.754----Test: 93.610\n",
            "\n",
            "09/27 10:27:41 PM | Epoch: 46/89---Train:99.754----Test: 93.610\n",
            "\n",
            "INFO:gal:Epoch: 46/89---Train:99.754----Test: 93.610\n",
            "\n",
            "09/27 10:28:10 PM | Epoch: 47/89---Train:99.808----Test: 93.660\n",
            "\n",
            "09/27 10:28:10 PM | Epoch: 47/89---Train:99.808----Test: 93.660\n",
            "\n",
            "INFO:gal:Epoch: 47/89---Train:99.808----Test: 93.660\n",
            "\n",
            "09/27 10:28:37 PM | Epoch: 48/89---Train:99.854----Test: 93.620\n",
            "\n",
            "09/27 10:28:37 PM | Epoch: 48/89---Train:99.854----Test: 93.620\n",
            "\n",
            "INFO:gal:Epoch: 48/89---Train:99.854----Test: 93.620\n",
            "\n",
            "09/27 10:29:04 PM | Epoch: 49/89---Train:99.852----Test: 93.470\n",
            "\n",
            "09/27 10:29:04 PM | Epoch: 49/89---Train:99.852----Test: 93.470\n",
            "\n",
            "INFO:gal:Epoch: 49/89---Train:99.852----Test: 93.470\n",
            "\n",
            "09/27 10:29:31 PM | Epoch: 50/89---Train:99.814----Test: 93.710\n",
            "\n",
            "09/27 10:29:31 PM | Epoch: 50/89---Train:99.814----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 50/89---Train:99.814----Test: 93.710\n",
            "\n",
            "09/27 10:29:58 PM | Epoch: 51/89---Train:99.846----Test: 93.680\n",
            "\n",
            "09/27 10:29:58 PM | Epoch: 51/89---Train:99.846----Test: 93.680\n",
            "\n",
            "INFO:gal:Epoch: 51/89---Train:99.846----Test: 93.680\n",
            "\n",
            "09/27 10:30:26 PM | Epoch: 52/89---Train:99.870----Test: 93.670\n",
            "\n",
            "09/27 10:30:26 PM | Epoch: 52/89---Train:99.870----Test: 93.670\n",
            "\n",
            "INFO:gal:Epoch: 52/89---Train:99.870----Test: 93.670\n",
            "\n",
            "09/27 10:30:54 PM | Epoch: 53/89---Train:99.888----Test: 93.800\n",
            "\n",
            "09/27 10:30:54 PM | Epoch: 53/89---Train:99.888----Test: 93.800\n",
            "\n",
            "INFO:gal:Epoch: 53/89---Train:99.888----Test: 93.800\n",
            "\n",
            "09/27 10:31:21 PM | Epoch: 54/89---Train:99.894----Test: 93.640\n",
            "\n",
            "09/27 10:31:21 PM | Epoch: 54/89---Train:99.894----Test: 93.640\n",
            "\n",
            "INFO:gal:Epoch: 54/89---Train:99.894----Test: 93.640\n",
            "\n",
            "09/27 10:31:48 PM | Epoch: 55/89---Train:99.888----Test: 93.680\n",
            "\n",
            "09/27 10:31:48 PM | Epoch: 55/89---Train:99.888----Test: 93.680\n",
            "\n",
            "INFO:gal:Epoch: 55/89---Train:99.888----Test: 93.680\n",
            "\n",
            "09/27 10:32:15 PM | Epoch: 56/89---Train:99.880----Test: 93.660\n",
            "\n",
            "09/27 10:32:15 PM | Epoch: 56/89---Train:99.880----Test: 93.660\n",
            "\n",
            "INFO:gal:Epoch: 56/89---Train:99.880----Test: 93.660\n",
            "\n",
            "09/27 10:32:43 PM | Epoch: 57/89---Train:99.914----Test: 93.660\n",
            "\n",
            "09/27 10:32:43 PM | Epoch: 57/89---Train:99.914----Test: 93.660\n",
            "\n",
            "INFO:gal:Epoch: 57/89---Train:99.914----Test: 93.660\n",
            "\n",
            "09/27 10:33:10 PM | Epoch: 58/89---Train:99.922----Test: 93.620\n",
            "\n",
            "09/27 10:33:10 PM | Epoch: 58/89---Train:99.922----Test: 93.620\n",
            "\n",
            "INFO:gal:Epoch: 58/89---Train:99.922----Test: 93.620\n",
            "\n",
            "09/27 10:33:38 PM | Epoch: 59/89---Train:99.928----Test: 93.650\n",
            "\n",
            "09/27 10:33:38 PM | Epoch: 59/89---Train:99.928----Test: 93.650\n",
            "\n",
            "INFO:gal:Epoch: 59/89---Train:99.928----Test: 93.650\n",
            "\n",
            "09/27 10:34:05 PM | Epoch: 60/89---Train:99.900----Test: 93.710\n",
            "\n",
            "09/27 10:34:05 PM | Epoch: 60/89---Train:99.900----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 60/89---Train:99.900----Test: 93.710\n",
            "\n",
            "09/27 10:34:32 PM | Epoch: 61/89---Train:99.936----Test: 93.780\n",
            "\n",
            "09/27 10:34:32 PM | Epoch: 61/89---Train:99.936----Test: 93.780\n",
            "\n",
            "INFO:gal:Epoch: 61/89---Train:99.936----Test: 93.780\n",
            "\n",
            "09/27 10:34:59 PM | Epoch: 62/89---Train:99.934----Test: 93.730\n",
            "\n",
            "09/27 10:34:59 PM | Epoch: 62/89---Train:99.934----Test: 93.730\n",
            "\n",
            "INFO:gal:Epoch: 62/89---Train:99.934----Test: 93.730\n",
            "\n",
            "09/27 10:35:27 PM | Epoch: 63/89---Train:99.932----Test: 93.580\n",
            "\n",
            "09/27 10:35:27 PM | Epoch: 63/89---Train:99.932----Test: 93.580\n",
            "\n",
            "INFO:gal:Epoch: 63/89---Train:99.932----Test: 93.580\n",
            "\n",
            "09/27 10:35:54 PM | Epoch: 64/89---Train:99.944----Test: 93.680\n",
            "\n",
            "09/27 10:35:54 PM | Epoch: 64/89---Train:99.944----Test: 93.680\n",
            "\n",
            "INFO:gal:Epoch: 64/89---Train:99.944----Test: 93.680\n",
            "\n",
            "09/27 10:36:21 PM | Epoch: 65/89---Train:99.928----Test: 93.650\n",
            "\n",
            "09/27 10:36:21 PM | Epoch: 65/89---Train:99.928----Test: 93.650\n",
            "\n",
            "INFO:gal:Epoch: 65/89---Train:99.928----Test: 93.650\n",
            "\n",
            "09/27 10:36:48 PM | Epoch: 66/89---Train:99.926----Test: 93.700\n",
            "\n",
            "09/27 10:36:48 PM | Epoch: 66/89---Train:99.926----Test: 93.700\n",
            "\n",
            "INFO:gal:Epoch: 66/89---Train:99.926----Test: 93.700\n",
            "\n",
            "09/27 10:37:15 PM | Epoch: 67/89---Train:99.950----Test: 93.620\n",
            "\n",
            "09/27 10:37:15 PM | Epoch: 67/89---Train:99.950----Test: 93.620\n",
            "\n",
            "INFO:gal:Epoch: 67/89---Train:99.950----Test: 93.620\n",
            "\n",
            "09/27 10:37:43 PM | Epoch: 68/89---Train:99.916----Test: 93.730\n",
            "\n",
            "09/27 10:37:43 PM | Epoch: 68/89---Train:99.916----Test: 93.730\n",
            "\n",
            "INFO:gal:Epoch: 68/89---Train:99.916----Test: 93.730\n",
            "\n",
            "09/27 10:38:10 PM | Epoch: 69/89---Train:99.932----Test: 93.710\n",
            "\n",
            "09/27 10:38:10 PM | Epoch: 69/89---Train:99.932----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 69/89---Train:99.932----Test: 93.710\n",
            "\n",
            "09/27 10:38:37 PM | Epoch: 70/89---Train:99.930----Test: 93.700\n",
            "\n",
            "09/27 10:38:37 PM | Epoch: 70/89---Train:99.930----Test: 93.700\n",
            "\n",
            "INFO:gal:Epoch: 70/89---Train:99.930----Test: 93.700\n",
            "\n",
            "09/27 10:39:04 PM | Epoch: 71/89---Train:99.944----Test: 93.760\n",
            "\n",
            "09/27 10:39:04 PM | Epoch: 71/89---Train:99.944----Test: 93.760\n",
            "\n",
            "INFO:gal:Epoch: 71/89---Train:99.944----Test: 93.760\n",
            "\n",
            "09/27 10:39:31 PM | Epoch: 72/89---Train:99.964----Test: 93.720\n",
            "\n",
            "09/27 10:39:31 PM | Epoch: 72/89---Train:99.964----Test: 93.720\n",
            "\n",
            "INFO:gal:Epoch: 72/89---Train:99.964----Test: 93.720\n",
            "\n",
            "09/27 10:39:59 PM | Epoch: 73/89---Train:99.946----Test: 93.750\n",
            "\n",
            "09/27 10:39:59 PM | Epoch: 73/89---Train:99.946----Test: 93.750\n",
            "\n",
            "INFO:gal:Epoch: 73/89---Train:99.946----Test: 93.750\n",
            "\n",
            "09/27 10:40:26 PM | Epoch: 74/89---Train:99.956----Test: 93.700\n",
            "\n",
            "09/27 10:40:26 PM | Epoch: 74/89---Train:99.956----Test: 93.700\n",
            "\n",
            "INFO:gal:Epoch: 74/89---Train:99.956----Test: 93.700\n",
            "\n",
            "09/27 10:40:52 PM | Epoch: 75/89---Train:99.960----Test: 93.670\n",
            "\n",
            "09/27 10:40:52 PM | Epoch: 75/89---Train:99.960----Test: 93.670\n",
            "\n",
            "INFO:gal:Epoch: 75/89---Train:99.960----Test: 93.670\n",
            "\n",
            "09/27 10:41:19 PM | Epoch: 76/89---Train:99.954----Test: 93.710\n",
            "\n",
            "09/27 10:41:19 PM | Epoch: 76/89---Train:99.954----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 76/89---Train:99.954----Test: 93.710\n",
            "\n",
            "09/27 10:41:46 PM | Epoch: 77/89---Train:99.964----Test: 93.710\n",
            "\n",
            "09/27 10:41:46 PM | Epoch: 77/89---Train:99.964----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 77/89---Train:99.964----Test: 93.710\n",
            "\n",
            "09/27 10:42:14 PM | Epoch: 78/89---Train:99.948----Test: 93.740\n",
            "\n",
            "09/27 10:42:14 PM | Epoch: 78/89---Train:99.948----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 78/89---Train:99.948----Test: 93.740\n",
            "\n",
            "09/27 10:42:41 PM | Epoch: 79/89---Train:99.964----Test: 93.610\n",
            "\n",
            "09/27 10:42:41 PM | Epoch: 79/89---Train:99.964----Test: 93.610\n",
            "\n",
            "INFO:gal:Epoch: 79/89---Train:99.964----Test: 93.610\n",
            "\n",
            "09/27 10:43:08 PM | Epoch: 80/89---Train:99.952----Test: 93.710\n",
            "\n",
            "09/27 10:43:08 PM | Epoch: 80/89---Train:99.952----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 80/89---Train:99.952----Test: 93.710\n",
            "\n",
            "09/27 10:43:35 PM | Epoch: 81/89---Train:99.938----Test: 93.750\n",
            "\n",
            "09/27 10:43:35 PM | Epoch: 81/89---Train:99.938----Test: 93.750\n",
            "\n",
            "INFO:gal:Epoch: 81/89---Train:99.938----Test: 93.750\n",
            "\n",
            "09/27 10:44:02 PM | Epoch: 82/89---Train:99.944----Test: 93.640\n",
            "\n",
            "09/27 10:44:02 PM | Epoch: 82/89---Train:99.944----Test: 93.640\n",
            "\n",
            "INFO:gal:Epoch: 82/89---Train:99.944----Test: 93.640\n",
            "\n",
            "09/27 10:44:30 PM | Epoch: 83/89---Train:99.972----Test: 93.710\n",
            "\n",
            "09/27 10:44:30 PM | Epoch: 83/89---Train:99.972----Test: 93.710\n",
            "\n",
            "INFO:gal:Epoch: 83/89---Train:99.972----Test: 93.710\n",
            "\n",
            "09/27 10:44:57 PM | Epoch: 84/89---Train:99.964----Test: 93.750\n",
            "\n",
            "09/27 10:44:57 PM | Epoch: 84/89---Train:99.964----Test: 93.750\n",
            "\n",
            "INFO:gal:Epoch: 84/89---Train:99.964----Test: 93.750\n",
            "\n",
            "09/27 10:45:24 PM | Epoch: 85/89---Train:99.950----Test: 93.730\n",
            "\n",
            "09/27 10:45:24 PM | Epoch: 85/89---Train:99.950----Test: 93.730\n",
            "\n",
            "INFO:gal:Epoch: 85/89---Train:99.950----Test: 93.730\n",
            "\n",
            "09/27 10:45:51 PM | Epoch: 86/89---Train:99.976----Test: 93.670\n",
            "\n",
            "09/27 10:45:51 PM | Epoch: 86/89---Train:99.976----Test: 93.670\n",
            "\n",
            "INFO:gal:Epoch: 86/89---Train:99.976----Test: 93.670\n",
            "\n",
            "09/27 10:46:18 PM | Epoch: 87/89---Train:99.970----Test: 93.790\n",
            "\n",
            "09/27 10:46:18 PM | Epoch: 87/89---Train:99.970----Test: 93.790\n",
            "\n",
            "INFO:gal:Epoch: 87/89---Train:99.970----Test: 93.790\n",
            "\n",
            "09/27 10:46:45 PM | Epoch: 88/89---Train:99.950----Test: 93.740\n",
            "\n",
            "09/27 10:46:45 PM | Epoch: 88/89---Train:99.950----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 88/89---Train:99.950----Test: 93.740\n",
            "\n",
            "09/27 10:47:13 PM | Epoch: 89/89---Train:99.968----Test: 93.740\n",
            "\n",
            "09/27 10:47:13 PM | Epoch: 89/89---Train:99.968----Test: 93.740\n",
            "\n",
            "INFO:gal:Epoch: 89/89---Train:99.968----Test: 93.740\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 10:50:54 PM | [23, 53, 124, 128, 256, 256, 256, 364, 159, 103, 129, 135, 144]\n",
            "09/27 10:50:54 PM | [23, 53, 124, 128, 256, 256, 256, 364, 159, 103, 129, 135, 144]\n",
            "INFO:gal:[23, 53, 124, 128, 256, 256, 256, 364, 159, 103, 129, 135, 144]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "new-model starts....for  90  epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "09/27 10:51:20 PM | Epoch: 0/89---Train:96.336----Test: 89.410\n",
            "\n",
            "09/27 10:51:20 PM | Epoch: 0/89---Train:96.336----Test: 89.410\n",
            "\n",
            "INFO:gal:Epoch: 0/89---Train:96.336----Test: 89.410\n",
            "\n",
            "09/27 10:51:47 PM | Epoch: 1/89---Train:96.322----Test: 89.590\n",
            "\n",
            "09/27 10:51:47 PM | Epoch: 1/89---Train:96.322----Test: 89.590\n",
            "\n",
            "INFO:gal:Epoch: 1/89---Train:96.322----Test: 89.590\n",
            "\n",
            "09/27 10:52:12 PM | Epoch: 2/89---Train:96.602----Test: 89.500\n",
            "\n",
            "09/27 10:52:12 PM | Epoch: 2/89---Train:96.602----Test: 89.500\n",
            "\n",
            "INFO:gal:Epoch: 2/89---Train:96.602----Test: 89.500\n",
            "\n",
            "09/27 10:52:38 PM | Epoch: 3/89---Train:96.606----Test: 89.360\n",
            "\n",
            "09/27 10:52:38 PM | Epoch: 3/89---Train:96.606----Test: 89.360\n",
            "\n",
            "INFO:gal:Epoch: 3/89---Train:96.606----Test: 89.360\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "# from VGG16 import VGG16\n",
        "import csv\n",
        "from itertools import zip_longest\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "seed =1787\n",
        "random.seed(seed)\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "th.manual_seed(seed)\n",
        "th.cuda.manual_seed(seed)\n",
        "th.cuda.manual_seed_all(seed)\n",
        "th.backends.cudnn.deterministic = True\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "N = 1\n",
        "batch_size_tr = 100\n",
        "batch_size_te = 100\n",
        "epochs = 2#300\n",
        "\n",
        "threshold= 0.54\n",
        "new_epochs=90#90-custom_epochs\n",
        "\n",
        "\n",
        "th.cuda.set_device(0)\n",
        "gpu = th.cuda.is_available()\n",
        "\n",
        "if not gpu:\n",
        "    print('qqqq')\n",
        "\n",
        "else:\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = th.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = th.utils.data.DataLoader(testset, batch_size=100, shuffle=True, num_workers=2) \n",
        "\n",
        "\n",
        "total_layers=15\n",
        "total_convs=13\n",
        "total_blocks=total_convs\n",
        "\n",
        "decision_count=th.ones((total_convs))\n",
        "\n",
        "short=False\n",
        "tr_size = 50000\n",
        "te_size=10000\n",
        "\n",
        "\n",
        "activation = 'relu'\n",
        "\n",
        "#tr_size = 300\n",
        "#te_size=300\n",
        "#short=True\n",
        "\n",
        "if gpu:\n",
        "    model=VGG16(10,activation).cuda()\n",
        "else:\n",
        "    model=VGG16(10,activation)\n",
        "\n",
        "folder_name=model.create_folders(total_convs)\n",
        "logger=model.get_logger(folder_name+'logger.log')\n",
        "\n",
        "optimizer = th.optim.SGD(model.parameters(), lr=0.1,momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = MultiStepLR(optimizer, milestones=[80,140,230], gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#ans=input(\"load from pretrained model= (t)true or (f)false\")\n",
        "ans='t'\n",
        "if(ans=='t'):\n",
        "  checkpoint = th.load('epoch_295.pth'\n",
        "                       # ,map_location=torch.device('cpu')\n",
        "                       )\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "  epoch_train_acc = checkpoint['train_acc']\n",
        "  epoch_test_acc = checkpoint['test_acc']\n",
        "  print('loading completed')\n",
        "\n",
        "elif(ans=='f'):\n",
        "\n",
        "    best_train_acc=0\n",
        "    best_test_acc=0\n",
        "    for n in range(N):\n",
        "\n",
        "        #current_iteration = 0\n",
        "        mi_iteration=0\n",
        "        for epoch in range(epochs):\n",
        "          #start=current_iteration\n",
        "          train_acc=[]\n",
        "          for batch_num, (inputs, targets) in enumerate(trainloader):\n",
        "            if(batch_num==3 and short):\n",
        "              break\n",
        "            if(batch_num%100==0):\n",
        "              print(batch_num)\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            with th.no_grad():\n",
        "              y_hat = th.argmax(output, 1)\n",
        "              score = th.eq(y_hat, targets).sum()\n",
        "              train_acc.append(score.item())\n",
        "              #current_iteration += 1\n",
        "          \n",
        "          with th.no_grad():\n",
        "            #model.train_accuracy.append((sum(train_acc)*100)/tr_size) \n",
        "            epoch_train_acc=  (sum(train_acc)*100)/tr_size        \n",
        "            test_acc=[]\n",
        "            model.eval()\n",
        "            for batch_nums, (inputs2, targets2) in enumerate(testloader):\n",
        "                if(batch_nums==3 and short):\n",
        "                    break\n",
        "\n",
        "                inputs2, targets2 = inputs2.cuda(), targets2.cuda()            \n",
        "                output=model(inputs2)\n",
        "                y_hat = th.argmax(output, 1)\n",
        "                score = th.eq(y_hat, targets2).sum()\n",
        "                test_acc.append(score.item())\n",
        "\n",
        "            #model.test_accuracy.append((sum(test_acc)*100)/te_size)\n",
        "            epoch_test_acc= (sum(test_acc)*100)/te_size\n",
        "            '''if(epoch_test_acc > best_test_acc ):\n",
        "              best_test_acc=epoch_test_acc\n",
        "              best_train_acc=epoch_train_acc '''      \n",
        "\n",
        "          #end=current_iteration\n",
        "          print('\\n---------------Epoch number: {}'.format(epoch),\n",
        "                  '---Train accuracy: {}'.format(epoch_train_acc),\n",
        "                  '----Test accuracy: {}'.format(epoch_test_acc),'--------------')\n",
        "          scheduler.step()\n",
        "          print(optimizer.param_groups[0]['lr'])\n",
        "else:\n",
        "   print('wrong ans entered')\n",
        "   import sys\n",
        "   sys.exit()\n",
        "\n",
        "#ended_epoch=epoch\n",
        "#ended_iteration=end\n",
        "prunes=0\n",
        "\n",
        "#_____________________Conv_layers_________________\n",
        "a=[]\n",
        "for layer_name, layer_module in model.named_modules():\n",
        "  if(isinstance(layer_module, th.nn.Conv2d)):\n",
        "    a.append(layer_module)\n",
        "\n",
        "\n",
        "\n",
        "d=[]\n",
        "for i in range(total_convs):\n",
        "      d.append(a[i].weight.shape[0])\n",
        "\n",
        "d.append(epoch_train_acc)\n",
        "d.append(epoch_test_acc)\n",
        "\n",
        "\n",
        "with open(folder_name+'vggPrune.csv', 'a', newline='') as myfile:\n",
        "          wr = csv.writer(myfile)\n",
        "          command=model.get_writerow(total_convs+2)\n",
        "          eval(command)\n",
        "myfile.close()\n",
        "\n",
        "ended_epoch=0\n",
        "best_train_acc=epoch_train_acc\n",
        "best_test_acc=epoch_test_acc\n",
        "\n",
        "state = {'model': model.state_dict(),\n",
        "          'train_acc': best_train_acc,\n",
        "          'test_acc':best_test_acc,\n",
        "          'optimizer':optimizer.state_dict(),\n",
        "          'scheduler':scheduler.state_dict()}\n",
        "#th.save(state,folder_name+'initial_pruning.pth')\n",
        "\n",
        "decision=True\n",
        "best_test_acc=0.0\n",
        "\n",
        "'''with th.no_grad():\n",
        "   final_first_ele =[]\n",
        "   final_n_clusters=[]\n",
        "   for layer_name, layer_module in model.named_modules():\n",
        "          \n",
        "          if(isinstance(layer_module, th.nn.Conv2d)):\n",
        " \n",
        "                  #--------clustering to find indices-------\n",
        "                  \n",
        "                  clusters, ele = model.cluster_weights_agglo(layer_module.weight, threshold)\n",
        "\n",
        "                  final_clusters.append(clusters)               \n",
        "                  final_first_ele.append(ele)'''\n",
        "\n",
        "\n",
        "while(decision==True):\n",
        "\n",
        "\n",
        "    with th.no_grad():\n",
        "      \n",
        "      #_________________________PRUNING_EACH_CONV_LAYER__________________________     \n",
        " \n",
        "      model.prune_filters(threshold,prunes,folder_name)\n",
        "            \n",
        "\n",
        "      #if(th.sum(decision_count)!=0):\n",
        "      if(prunes==25):\n",
        "          decision=False  \n",
        " \n",
        "      prunes+=1\n",
        "\n",
        "    d1=[]\n",
        "    for i1 in range(total_convs):\n",
        "      d1.append(a[i1].weight.shape[0])\n",
        "    logger.info(d1)\n",
        "\n",
        "    print('new-model starts....for ',new_epochs,' epochs')\n",
        "    #print(model)\n",
        "\n",
        "    optimizer = th.optim.SGD(model.parameters(), lr=0.01,momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = MultiStepLR(optimizer, milestones=[40,70,90], gamma=0.1)\n",
        "    #optimizer = th.optim.SGD(model.parameters(), lr=0.001,momentum=0.9, weight_decay=5e-4)\n",
        "    #scheduler = MultiStepLR(optimizer, milestones=[40,70,90], gamma=0.1)\n",
        "    \n",
        "    best_test_acc=0.0\n",
        "\n",
        "    for epoch in range(new_epochs):\n",
        "\n",
        "          train_acc=[]\n",
        "          test_acc=[]\n",
        "\n",
        "          for batch_num, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "            if(batch_num==3 and short):\n",
        "               break\n",
        "\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "            model= model.cuda()\n",
        "            model.train()            \n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            with th.no_grad():\n",
        "\n",
        "               y_hat = th.argmax(output, 1)\n",
        "               score = th.eq(y_hat, targets).sum()\n",
        "               train_acc.append(score.item())\n",
        "     \n",
        "\n",
        "          with th.no_grad():            \n",
        "\n",
        "\n",
        "              epoch_train_acc=(sum(train_acc)*100)/tr_size\n",
        "              model.eval() \n",
        "          \n",
        "              for batch_idx2, (inputs2, targets2) in enumerate(testloader):\n",
        "                if(batch_idx2==3 and short):\n",
        "                    break\n",
        "                inputs2, targets2 = inputs2.cuda(), targets2.cuda()\n",
        "                output=model(inputs2)\n",
        "                y_hat = th.argmax(output, 1)\n",
        "                score = th.eq(y_hat, targets2).sum()\n",
        "                test_acc.append(score.item())\n",
        "\n",
        "              epoch_test_acc=(sum(test_acc)*100)/te_size\n",
        "              if(epoch_test_acc > best_test_acc ):\n",
        "                      best_test_acc=epoch_test_acc\n",
        "                      best_train_acc=epoch_train_acc\n",
        "                      #state = {'model': model.state_dict(),\n",
        "                      #         'train_acc': best_train_acc,\n",
        "                      #         'test_acc':best_test_acc,\n",
        "                      #         'optimizer':optimizer.state_dict(),\n",
        "                      #         'scheduler':scheduler.state_dict()}\n",
        "                      #th.save(state,folder_name+str(prunes)+'.pth')\n",
        "\n",
        "          #print(optimizer.param_groups[0]['lr'])\n",
        "          scheduler.step()\n",
        "          \n",
        "          logger.info('Epoch: {}/{}---Train:{:.3f}----Test: {:.3f}\\n'.format(epoch,new_epochs-1,epoch_train_acc,epoch_test_acc))\n",
        "\n",
        "\n",
        "    #----------------writing data-----------\n",
        "    ended_epoch=ended_epoch+new_epochs\n",
        "\n",
        "    d=[]\n",
        "    for i in range(total_convs):\n",
        "      d.append(a[i].weight.shape[0])\n",
        "    d.append(best_train_acc)\n",
        "    d.append(best_test_acc)\n",
        "    with open(folder_name+'vggPrune.csv', 'a', newline='') as myfile:\n",
        "          wr = csv.writer(myfile)\n",
        "          command=model.get_writerow(total_convs+2)\n",
        "          eval(command)\n",
        "\n",
        "    myfile.close()\n",
        "    #-------------------------end writing data---------------\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import os,glob\n",
        "\n",
        "directory = os.path.dirname(os.path.realpath(__file__)) #location of running file\n",
        "file_paths = []\n",
        "os.chdir(directory)\n",
        "for filename in glob.glob(\"*.py\"):\n",
        "\tfilepath = os.path.join(directory, filename)\n",
        "\tfile_paths.append(filepath)\n",
        "\t#print(filename)\n",
        "\n",
        "print('Following files will be zipped:')\n",
        "for file_name in file_paths:\n",
        "\tprint(file_name)\n",
        "saving_loc = folder_name #location of results\n",
        "os.chdir(saving_loc)\n",
        "# writing files to a zipfile\n",
        "with ZipFile('python_files.zip','w') as zip:\n",
        "\t# writing each file one by one\n",
        "\tfor file in file_paths:\n",
        "\t\tzip.write(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVGSitrCIfsC"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv1\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySppyqRTkE8M"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv2\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgV-IPLvkRUE"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv3\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEoWWTG9kSFE"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv4\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmfUxUR6kURl"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv5\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-MGTvGdkWLJ"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv6\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yavtQYSkXVW"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv7\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0VB7EXakYnA"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv8\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtZ6jVQdkZjm"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv9\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVz_MGErkaZX"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv10\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN-hq6L-kbR7"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv11\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0pSYJBjkcZS"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv12\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG2eQR9Dkd-2"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/\\Results\\Sep27_18_18_02PM_vggconv13\" \"/content/drive/MyDrive/btpsem7data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nsQ74bhkfig"
      },
      "outputs": [],
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEfprkkynZ3b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}